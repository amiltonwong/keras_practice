{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Tensorflow tutorial: Practical guide from getting started to developing complex deep neural network\n",
    "http://cv-tricks.com/tensorflow-tutorial/keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " edit \"~/.keras/keras.json\" to switch  between tensorflow or theano as backends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has two distinct ways of building models\n",
    "1. Sequential model: This is used to implement simple models. You simply keep adding layers to the existing model\n",
    "2. Functional API: To build more complex models using it, models with multiple output, directed acyclic graph etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by importing and building a Sequential model.\n",
    "\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add layers like Dense(fully connected layer), Activation, Conv2D, MaxPooling2D etc \n",
    "# by calling add function.\n",
    "\n",
    "from keras.layers import Dense, Activation,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(224,224,3)))\n",
    "# This adds a Convolutional layer with 64 filters of size 3 * 3 to the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify the optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the ‘rmsprop’ optimizer to change weights in such a way that the loss \n",
    "# binary_crossentropy’ is minimized at each iteration\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to specify stochastic gradient descent and you want to choose proper \n",
    "# initialization and other hyperparameters:\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feed the data to the model via the fit function\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the evaluate function to test the model\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve a linear regression problem with an example\n",
    "For this example, we will create 100 data points and try to fit them into a line.\n",
    "TrainX has values between –1 and 1, and TrainY has 3 times the TrainX and some randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training data\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    " \n",
    "trX = np.linspace(-1, 1, 101)\n",
    "trY = 3 * trX + np.random.randn(*trX.shape) * 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", input_dim=1, units=1, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=1, output_dim=1, init='uniform', activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model is initialized with weights w: 0.02, b: 0.00\n"
     ]
    }
   ],
   "source": [
    "weights = model.layers[0].get_weights()\n",
    "w_init = weights[0][0][0]\n",
    "b_init = weights[1][0]\n",
    "print('Linear regression model is initialized with weights w: %.2f, b: %.2f' % (w_init, b_init)) \n",
    "## Linear regression model is initialized with weight w: -0.01, b: 0.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train this linear model with our training data of trX and trY,\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "101/101 [==============================] - 0s - loss: 3.2189     \n",
      "Epoch 2/200\n",
      "101/101 [==============================] - 0s - loss: 3.0469     \n",
      "Epoch 3/200\n",
      "101/101 [==============================] - 0s - loss: 2.8702     \n",
      "Epoch 4/200\n",
      "101/101 [==============================] - 0s - loss: 2.7191     \n",
      "Epoch 5/200\n",
      "101/101 [==============================] - 0s - loss: 2.5617     \n",
      "Epoch 6/200\n",
      "101/101 [==============================] - 0s - loss: 2.4239     \n",
      "Epoch 7/200\n",
      "101/101 [==============================] - 0s - loss: 2.2941     \n",
      "Epoch 8/200\n",
      "101/101 [==============================] - 0s - loss: 2.1832     \n",
      "Epoch 9/200\n",
      "101/101 [==============================] - 0s - loss: 2.0672     \n",
      "Epoch 10/200\n",
      "101/101 [==============================] - 0s - loss: 1.9609     \n",
      "Epoch 11/200\n",
      "101/101 [==============================] - 0s - loss: 1.8562     \n",
      "Epoch 12/200\n",
      "101/101 [==============================] - 0s - loss: 1.7678     \n",
      "Epoch 13/200\n",
      "101/101 [==============================] - 0s - loss: 1.6724     \n",
      "Epoch 14/200\n",
      "101/101 [==============================] - 0s - loss: 1.5893     \n",
      "Epoch 15/200\n",
      "101/101 [==============================] - 0s - loss: 1.5077     \n",
      "Epoch 16/200\n",
      "101/101 [==============================] - 0s - loss: 1.4366     \n",
      "Epoch 17/200\n",
      "101/101 [==============================] - 0s - loss: 1.3702     \n",
      "Epoch 18/200\n",
      "101/101 [==============================] - 0s - loss: 1.3066     \n",
      "Epoch 19/200\n",
      "101/101 [==============================] - 0s - loss: 1.2431     \n",
      "Epoch 20/200\n",
      "101/101 [==============================] - 0s - loss: 1.1778     \n",
      "Epoch 21/200\n",
      "101/101 [==============================] - 0s - loss: 1.1183     \n",
      "Epoch 22/200\n",
      "101/101 [==============================] - 0s - loss: 1.0541     \n",
      "Epoch 23/200\n",
      "101/101 [==============================] - 0s - loss: 1.0060     \n",
      "Epoch 24/200\n",
      "101/101 [==============================] - 0s - loss: 0.9599     \n",
      "Epoch 25/200\n",
      "101/101 [==============================] - 0s - loss: 0.9109     \n",
      "Epoch 26/200\n",
      "101/101 [==============================] - 0s - loss: 0.8612     \n",
      "Epoch 27/200\n",
      "101/101 [==============================] - 0s - loss: 0.8227     \n",
      "Epoch 28/200\n",
      "101/101 [==============================] - 0s - loss: 0.7848     \n",
      "Epoch 29/200\n",
      "101/101 [==============================] - 0s - loss: 0.7498     \n",
      "Epoch 30/200\n",
      "101/101 [==============================] - 0s - loss: 0.7123     \n",
      "Epoch 31/200\n",
      "101/101 [==============================] - 0s - loss: 0.6809     \n",
      "Epoch 32/200\n",
      "101/101 [==============================] - 0s - loss: 0.6500     \n",
      "Epoch 33/200\n",
      "101/101 [==============================] - 0s - loss: 0.6185     \n",
      "Epoch 34/200\n",
      "101/101 [==============================] - 0s - loss: 0.5894     \n",
      "Epoch 35/200\n",
      "101/101 [==============================] - 0s - loss: 0.5648     \n",
      "Epoch 36/200\n",
      "101/101 [==============================] - 0s - loss: 0.5424     \n",
      "Epoch 37/200\n",
      "101/101 [==============================] - 0s - loss: 0.5201     \n",
      "Epoch 38/200\n",
      "101/101 [==============================] - 0s - loss: 0.4978     \n",
      "Epoch 39/200\n",
      "101/101 [==============================] - 0s - loss: 0.4754     \n",
      "Epoch 40/200\n",
      "101/101 [==============================] - 0s - loss: 0.4562     \n",
      "Epoch 41/200\n",
      "101/101 [==============================] - 0s - loss: 0.4371     \n",
      "Epoch 42/200\n",
      "101/101 [==============================] - 0s - loss: 0.4173     \n",
      "Epoch 43/200\n",
      "101/101 [==============================] - 0s - loss: 0.4009     \n",
      "Epoch 44/200\n",
      "101/101 [==============================] - 0s - loss: 0.3835     \n",
      "Epoch 45/200\n",
      "101/101 [==============================] - 0s - loss: 0.3693     \n",
      "Epoch 46/200\n",
      "101/101 [==============================] - 0s - loss: 0.3550     \n",
      "Epoch 47/200\n",
      "101/101 [==============================] - 0s - loss: 0.3403     \n",
      "Epoch 48/200\n",
      "101/101 [==============================] - 0s - loss: 0.3288     \n",
      "Epoch 49/200\n",
      "101/101 [==============================] - 0s - loss: 0.3159     \n",
      "Epoch 50/200\n",
      "101/101 [==============================] - 0s - loss: 0.3011     \n",
      "Epoch 51/200\n",
      "101/101 [==============================] - 0s - loss: 0.2913     \n",
      "Epoch 52/200\n",
      "101/101 [==============================] - 0s - loss: 0.2816     \n",
      "Epoch 53/200\n",
      "101/101 [==============================] - 0s - loss: 0.2715     \n",
      "Epoch 54/200\n",
      "101/101 [==============================] - 0s - loss: 0.2628     \n",
      "Epoch 55/200\n",
      "101/101 [==============================] - 0s - loss: 0.2541     \n",
      "Epoch 56/200\n",
      "101/101 [==============================] - 0s - loss: 0.2464     \n",
      "Epoch 57/200\n",
      "101/101 [==============================] - 0s - loss: 0.2396     \n",
      "Epoch 58/200\n",
      "101/101 [==============================] - 0s - loss: 0.2316     \n",
      "Epoch 59/200\n",
      "101/101 [==============================] - 0s - loss: 0.2245     \n",
      "Epoch 60/200\n",
      "101/101 [==============================] - 0s - loss: 0.2178     \n",
      "Epoch 61/200\n",
      "101/101 [==============================] - 0s - loss: 0.2110     \n",
      "Epoch 62/200\n",
      "101/101 [==============================] - 0s - loss: 0.2051     \n",
      "Epoch 63/200\n",
      "101/101 [==============================] - 0s - loss: 0.1992     \n",
      "Epoch 64/200\n",
      "101/101 [==============================] - 0s - loss: 0.1939     \n",
      "Epoch 65/200\n",
      "101/101 [==============================] - 0s - loss: 0.1893     \n",
      "Epoch 66/200\n",
      "101/101 [==============================] - 0s - loss: 0.1840     \n",
      "Epoch 67/200\n",
      "101/101 [==============================] - 0s - loss: 0.1789     \n",
      "Epoch 68/200\n",
      "101/101 [==============================] - 0s - loss: 0.1742     \n",
      "Epoch 69/200\n",
      "101/101 [==============================] - 0s - loss: 0.1697     \n",
      "Epoch 70/200\n",
      "101/101 [==============================] - 0s - loss: 0.1658     \n",
      "Epoch 71/200\n",
      "101/101 [==============================] - 0s - loss: 0.1620     \n",
      "Epoch 72/200\n",
      "101/101 [==============================] - 0s - loss: 0.1585     \n",
      "Epoch 73/200\n",
      "101/101 [==============================] - 0s - loss: 0.1550     \n",
      "Epoch 74/200\n",
      "101/101 [==============================] - 0s - loss: 0.1518     \n",
      "Epoch 75/200\n",
      "101/101 [==============================] - 0s - loss: 0.1487     \n",
      "Epoch 76/200\n",
      "101/101 [==============================] - 0s - loss: 0.1451     \n",
      "Epoch 77/200\n",
      "101/101 [==============================] - 0s - loss: 0.1427     \n",
      "Epoch 78/200\n",
      "101/101 [==============================] - 0s - loss: 0.1398     \n",
      "Epoch 79/200\n",
      "101/101 [==============================] - 0s - loss: 0.1374     \n",
      "Epoch 80/200\n",
      "101/101 [==============================] - 0s - loss: 0.1354     \n",
      "Epoch 81/200\n",
      "101/101 [==============================] - 0s - loss: 0.1326     \n",
      "Epoch 82/200\n",
      "101/101 [==============================] - 0s - loss: 0.1303     \n",
      "Epoch 83/200\n",
      "101/101 [==============================] - 0s - loss: 0.1282     \n",
      "Epoch 84/200\n",
      "101/101 [==============================] - 0s - loss: 0.1262     \n",
      "Epoch 85/200\n",
      "101/101 [==============================] - 0s - loss: 0.1246     \n",
      "Epoch 86/200\n",
      "101/101 [==============================] - 0s - loss: 0.1231     \n",
      "Epoch 87/200\n",
      "101/101 [==============================] - 0s - loss: 0.1217     \n",
      "Epoch 88/200\n",
      "101/101 [==============================] - 0s - loss: 0.1203     \n",
      "Epoch 89/200\n",
      "101/101 [==============================] - 0s - loss: 0.1188     \n",
      "Epoch 90/200\n",
      "101/101 [==============================] - 0s - loss: 0.1175     \n",
      "Epoch 91/200\n",
      "101/101 [==============================] - 0s - loss: 0.1164     \n",
      "Epoch 92/200\n",
      "101/101 [==============================] - 0s - loss: 0.1153     \n",
      "Epoch 93/200\n",
      "101/101 [==============================] - 0s - loss: 0.1139     \n",
      "Epoch 94/200\n",
      "101/101 [==============================] - 0s - loss: 0.1129     \n",
      "Epoch 95/200\n",
      "101/101 [==============================] - 0s - loss: 0.1117     \n",
      "Epoch 96/200\n",
      "101/101 [==============================] - 0s - loss: 0.1105     \n",
      "Epoch 97/200\n",
      "101/101 [==============================] - 0s - loss: 0.1092     \n",
      "Epoch 98/200\n",
      "101/101 [==============================] - 0s - loss: 0.1080     \n",
      "Epoch 99/200\n",
      "101/101 [==============================] - 0s - loss: 0.1071     \n",
      "Epoch 100/200\n",
      "101/101 [==============================] - 0s - loss: 0.1060     \n",
      "Epoch 101/200\n",
      "101/101 [==============================] - 0s - loss: 0.1053     \n",
      "Epoch 102/200\n",
      "101/101 [==============================] - 0s - loss: 0.1048     \n",
      "Epoch 103/200\n",
      "101/101 [==============================] - 0s - loss: 0.1040     \n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s - loss: 0.1036     \n",
      "Epoch 105/200\n",
      "101/101 [==============================] - 0s - loss: 0.1030     \n",
      "Epoch 106/200\n",
      "101/101 [==============================] - 0s - loss: 0.1027     \n",
      "Epoch 107/200\n",
      "101/101 [==============================] - 0s - loss: 0.1020     \n",
      "Epoch 108/200\n",
      "101/101 [==============================] - 0s - loss: 0.1017     \n",
      "Epoch 109/200\n",
      "101/101 [==============================] - 0s - loss: 0.1013     \n",
      "Epoch 110/200\n",
      "101/101 [==============================] - 0s - loss: 0.1009     \n",
      "Epoch 111/200\n",
      "101/101 [==============================] - 0s - loss: 0.1005     \n",
      "Epoch 112/200\n",
      "101/101 [==============================] - 0s - loss: 0.1003     \n",
      "Epoch 113/200\n",
      "101/101 [==============================] - 0s - loss: 0.1000     \n",
      "Epoch 114/200\n",
      "101/101 [==============================] - 0s - loss: 0.0998     \n",
      "Epoch 115/200\n",
      "101/101 [==============================] - 0s - loss: 0.0996     \n",
      "Epoch 116/200\n",
      "101/101 [==============================] - 0s - loss: 0.0992     \n",
      "Epoch 117/200\n",
      "101/101 [==============================] - 0s - loss: 0.0988     \n",
      "Epoch 118/200\n",
      "101/101 [==============================] - 0s - loss: 0.0985     \n",
      "Epoch 119/200\n",
      "101/101 [==============================] - 0s - loss: 0.0983     \n",
      "Epoch 120/200\n",
      "101/101 [==============================] - 0s - loss: 0.0979     \n",
      "Epoch 121/200\n",
      "101/101 [==============================] - 0s - loss: 0.0978     \n",
      "Epoch 122/200\n",
      "101/101 [==============================] - 0s - loss: 0.0974     \n",
      "Epoch 123/200\n",
      "101/101 [==============================] - 0s - loss: 0.0972     \n",
      "Epoch 124/200\n",
      "101/101 [==============================] - 0s - loss: 0.0969     \n",
      "Epoch 125/200\n",
      "101/101 [==============================] - 0s - loss: 0.0968     \n",
      "Epoch 126/200\n",
      "101/101 [==============================] - 0s - loss: 0.0965     \n",
      "Epoch 127/200\n",
      "101/101 [==============================] - 0s - loss: 0.0964     \n",
      "Epoch 128/200\n",
      "101/101 [==============================] - 0s - loss: 0.0962     \n",
      "Epoch 129/200\n",
      "101/101 [==============================] - 0s - loss: 0.0961     \n",
      "Epoch 130/200\n",
      "101/101 [==============================] - 0s - loss: 0.0961     \n",
      "Epoch 131/200\n",
      "101/101 [==============================] - 0s - loss: 0.0960     \n",
      "Epoch 132/200\n",
      "101/101 [==============================] - 0s - loss: 0.0958     \n",
      "Epoch 133/200\n",
      "101/101 [==============================] - ETA: 0s - loss: 0.090 - 0s - loss: 0.0957     \n",
      "Epoch 134/200\n",
      "101/101 [==============================] - 0s - loss: 0.0955     \n",
      "Epoch 135/200\n",
      "101/101 [==============================] - 0s - loss: 0.0956     \n",
      "Epoch 136/200\n",
      "101/101 [==============================] - 0s - loss: 0.0957     \n",
      "Epoch 137/200\n",
      "101/101 [==============================] - 0s - loss: 0.0956     \n",
      "Epoch 138/200\n",
      "101/101 [==============================] - 0s - loss: 0.0954     \n",
      "Epoch 139/200\n",
      "101/101 [==============================] - 0s - loss: 0.0954     \n",
      "Epoch 140/200\n",
      "101/101 [==============================] - 0s - loss: 0.0953     \n",
      "Epoch 141/200\n",
      "101/101 [==============================] - 0s - loss: 0.0950     \n",
      "Epoch 142/200\n",
      "101/101 [==============================] - 0s - loss: 0.0949     \n",
      "Epoch 143/200\n",
      "101/101 [==============================] - 0s - loss: 0.0948     \n",
      "Epoch 144/200\n",
      "101/101 [==============================] - 0s - loss: 0.0948     \n",
      "Epoch 145/200\n",
      "101/101 [==============================] - ETA: 0s - loss: 0.087 - 0s - loss: 0.0947     \n",
      "Epoch 146/200\n",
      "101/101 [==============================] - 0s - loss: 0.0946     \n",
      "Epoch 147/200\n",
      "101/101 [==============================] - 0s - loss: 0.0945     \n",
      "Epoch 148/200\n",
      "101/101 [==============================] - 0s - loss: 0.0945     \n",
      "Epoch 149/200\n",
      "101/101 [==============================] - 0s - loss: 0.0945     \n",
      "Epoch 150/200\n",
      "101/101 [==============================] - 0s - loss: 0.0944     \n",
      "Epoch 151/200\n",
      "101/101 [==============================] - 0s - loss: 0.0943     \n",
      "Epoch 152/200\n",
      "101/101 [==============================] - 0s - loss: 0.0943     \n",
      "Epoch 153/200\n",
      "101/101 [==============================] - 0s - loss: 0.0942     \n",
      "Epoch 154/200\n",
      "101/101 [==============================] - 0s - loss: 0.0942     \n",
      "Epoch 155/200\n",
      "101/101 [==============================] - 0s - loss: 0.0942     \n",
      "Epoch 156/200\n",
      "101/101 [==============================] - 0s - loss: 0.0942     \n",
      "Epoch 157/200\n",
      "101/101 [==============================] - 0s - loss: 0.0942     \n",
      "Epoch 158/200\n",
      "101/101 [==============================] - 0s - loss: 0.0941     \n",
      "Epoch 159/200\n",
      "101/101 [==============================] - 0s - loss: 0.0941     \n",
      "Epoch 160/200\n",
      "101/101 [==============================] - 0s - loss: 0.0941     \n",
      "Epoch 161/200\n",
      "101/101 [==============================] - 0s - loss: 0.0941     \n",
      "Epoch 162/200\n",
      "101/101 [==============================] - 0s - loss: 0.0940     \n",
      "Epoch 163/200\n",
      "101/101 [==============================] - 0s - loss: 0.0940     \n",
      "Epoch 164/200\n",
      "101/101 [==============================] - 0s - loss: 0.0941     \n",
      "Epoch 165/200\n",
      "101/101 [==============================] - 0s - loss: 0.0940     \n",
      "Epoch 166/200\n",
      "101/101 [==============================] - 0s - loss: 0.0940     \n",
      "Epoch 167/200\n",
      "101/101 [==============================] - 0s - loss: 0.0941     \n",
      "Epoch 168/200\n",
      "101/101 [==============================] - 0s - loss: 0.0941     \n",
      "Epoch 169/200\n",
      "101/101 [==============================] - 0s - loss: 0.0940     \n",
      "Epoch 170/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 171/200\n",
      "101/101 [==============================] - 0s - loss: 0.0940     \n",
      "Epoch 172/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 173/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 174/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 175/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 176/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 177/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 178/200\n",
      "101/101 [==============================] - 0s - loss: 0.0938     \n",
      "Epoch 179/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 180/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 181/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 182/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 183/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 184/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 185/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 186/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 187/200\n",
      "101/101 [==============================] - 0s - loss: 0.0940     \n",
      "Epoch 188/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 189/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 190/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 191/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 192/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 193/200\n",
      "101/101 [==============================] - 0s - loss: 0.0940     \n",
      "Epoch 194/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 195/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 196/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 197/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 198/200\n",
      "101/101 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 199/200\n",
      "101/101 [==============================] - 0s - loss: 0.0940     \n",
      "Epoch 200/200\n",
      "101/101 [==============================] - 0s - loss: 0.0938     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf4df4f3c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed the data using fit function\n",
    "\n",
    "model.fit(trX, trY, nb_epoch=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model is trained to have weight w: 3.00, b: -0.04\n"
     ]
    }
   ],
   "source": [
    "# print the weight after training\n",
    "\n",
    "weights = model.layers[0].get_weights()\n",
    "w_final = weights[0][0][0]\n",
    "b_final = weights[1][0]\n",
    "print('Linear regression model is trained to have weight w: %.2f, b: %.2f' % (w_final, b_final))\n",
    "     \n",
    "##Linear regression model is trained to have weight w: 2.94, b: 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3.00326824]], dtype=float32), array([-0.0362544], dtype=float32)]\n",
      "<class 'list'>\n",
      "2\n",
      "[[ 3.00326824]]\n",
      "(1, 1)\n",
      "[ 3.00326824]\n",
      "<class 'numpy.ndarray'>\n",
      "3.00327\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(weights)\n",
    "print(type(weights))\n",
    "print(len(weights))\n",
    "print(weights[0])\n",
    "print(weights[0].shape)\n",
    "print(weights[0][0])\n",
    "print(type(weights[0][0]))\n",
    "print(weights[0][0][0])\n",
    "print(type(weights[0][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and restoring pre-trained weights using Keras\n",
    "Once you are done with training using Keras, you can save your network weights in HDF5 binary data format. (Require: h5py package installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving weights:\n",
    "\n",
    "model.save_weights(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restoring pre-trained weights:\n",
    "\n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and restoring network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save as JSON into a network file\n",
    "\n",
    "json_string = model.to_json()\n",
    "\n",
    "import json\n",
    "with open('my_network.json', 'w') as outfile:\n",
    "    json.dump(json_string, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# restore from json str\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model2 = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional API:\n",
    "used for building complex model. Functional API allows you to call models like a function as we do for a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Previous Sequential example: from keras.models import Sequential\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specifying the input, as opposed to (previous) mentioning the input at the end of \n",
    "# the fit function as done in Sequential models\n",
    "\n",
    "from keras.layers import Input\n",
    "# First, define the vision modules\n",
    "\n",
    "# declare a tensor of shape 1 * 28 * 28 by using Input(), not including the batch size.\n",
    "digit_input = Input(shape=(28,28,1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply a convolutional layer using the Functional API, we shall have to \n",
    "# specify the variable on which we want to apply the layer\n",
    "\n",
    "x = Conv2D(64, (3, 3))(digit_input)\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "out = Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally,  create a model by specifying the input and output\n",
    "\n",
    "vision_model = Model(digit_input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to specify stochastic gradient descent and you want to choose proper \n",
    "# initialization and other hyperparameters:\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "vision_model.compile(loss='categorical_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-ecb65bc7418a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# feed the data to the model via the fit function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvision_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1430\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[1;32m   1315\u001b[0m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[0m\u001b[1;32m   1317\u001b[0m         \u001b[0m_check_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         _check_loss_and_target_compatibility(y,\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                                                    self._feed_output_names)\n\u001b[1;32m   1314\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[0;32m-> 1315\u001b[0;31m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[1;32m   1317\u001b[0m         \u001b[0m_check_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(y, sample_weight, class_weight, sample_weight_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# feed the data to the model via the fit function\n",
    "\n",
    "vision_model.fit(batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??vision_model.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop VGG convolutional neural network using functional API\n",
    "vgg-16 has 16 layers. As you can see that it takes an input of 224 * 224 * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/vgg16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Activation,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "import numpy as np\n",
    "\n",
    "input_shape = (224,224,3)\n",
    "classes = 1000\n",
    "\n",
    "img_input = Input(shape=input_shape)\n",
    "# Block 1\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "# Block 2\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "# Block 3\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "# Block 4\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "# Block 5\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = Dense(classes, activation='softmax', name='predictions')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-096361179438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvgg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m         \u001b[0;31m# Check for redundancy in inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m         \u001b[0minputs_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1486\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_set\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m             raise ValueError('The list of inputs passed to the model '\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "#vgg_model = Model(img_input, x)\n",
    "img = image.load_img('./img/cat.jpg', target_size=(224, 224))\n",
    "img_input = image.img_to_array(img)\n",
    "img_input = np.expand_dims(img_input, axis=0)\n",
    "vgg_model = Model(inputs=img_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'applications' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-2ac18653c132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'applications' is not defined"
     ]
    }
   ],
   "source": [
    "model = applications.VGG16(weights='imagenet')\n",
    "img = image.load_img('cat.jpeg', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model.predict(x)\n",
    "for results in decode_predictions(preds):\n",
    "    for result in results:\n",
    "        print('Probability %0.2f%% => [%s]' % (100*result[2], result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet 5 for mnist dataset\n",
    "keras_LeNet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 54s - loss: 0.1822 - acc: 0.9441 - val_loss: 0.0630 - val_acc: 0.9796\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 53s - loss: 0.0518 - acc: 0.9844 - val_loss: 0.0495 - val_acc: 0.9847\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 53s - loss: 0.0341 - acc: 0.9898 - val_loss: 0.0417 - val_acc: 0.9869\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 51s - loss: 0.0237 - acc: 0.9925 - val_loss: 0.0442 - val_acc: 0.9858\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0182 - acc: 0.9939 - val_loss: 0.0346 - val_acc: 0.9892\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0123 - acc: 0.9957 - val_loss: 0.0334 - val_acc: 0.9896\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0369 - val_acc: 0.9891\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0098 - acc: 0.9970 - val_loss: 0.0357 - val_acc: 0.9902\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0088 - acc: 0.9968 - val_loss: 0.0332 - val_acc: 0.9911\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0071 - acc: 0.9975 - val_loss: 0.0340 - val_acc: 0.9917\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0067 - acc: 0.9977 - val_loss: 0.0441 - val_acc: 0.9895\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0070 - acc: 0.9975 - val_loss: 0.0451 - val_acc: 0.9911\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0512 - val_acc: 0.9891\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 50s - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0412 - val_acc: 0.9916\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0444 - val_acc: 0.9897\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0416 - val_acc: 0.9918\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0453 - val_acc: 0.9917\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 50s - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0401 - val_acc: 0.9922\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 49s - loss: 0.0043 - acc: 0.9988 - val_loss: 0.0427 - val_acc: 0.9916\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 50s - loss: 0.0039 - acc: 0.9986 - val_loss: 0.0480 - val_acc: 0.9900\n",
      " 9856/10000 [============================>.] - ETA: 0s\n",
      "Test score: 0.0382239685618\n",
      "Test accuracy: 0.9902\n",
      "dict_keys(['acc', 'val_loss', 'loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neqVkISIivVKyEBGRXilZiIhIr/4/gcdlD1HZ1E4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96b84ac2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERFJyf8P/uAOGJAYD50AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96b859b828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1671)  # for reproducibility\n",
    "\n",
    "#define the convnet \n",
    "class LeNet:\n",
    "\t@staticmethod\n",
    "\tdef build(input_shape, classes):\n",
    "\t\tmodel = Sequential()\n",
    "\t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(Conv2D(20, kernel_size=5, padding=\"same\",\n",
    "\t\t\tinput_shape=input_shape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(Conv2D(50, kernel_size=5, padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\t\t# Flatten => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(500))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    " \n",
    "\t\t# a softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\treturn model\n",
    "\n",
    "# network and training\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "IMG_ROWS, IMG_COLS = 28, 28 # input image dimensions\n",
    "NB_CLASSES = 10  # number of outputs = number of digits\n",
    "#INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)\n",
    "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 1)\n",
    "# using tensorboard\n",
    "\n",
    "#tbCallBack = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#K.set_image_dim_ordering(\"th\")\n",
    "K.set_image_dim_ordering(\"tf\")\n",
    "\n",
    "# consider them as float and normalize\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 \n",
    "X_test /= 255  \n",
    "\n",
    "# we need a 60K x [1 x 28 x 28] shape as input to the CONVNET\n",
    "#X_train = X_train[:, np.newaxis, :, :]\n",
    "#X_test = X_test[:, np.newaxis, :, :]\n",
    "X_train = X_train[:,:, :, np.newaxis]\n",
    "X_test = X_test[:, :, :, np.newaxis]\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# initialize the optimizer and model\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH, \n",
    "        verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "        # use tensorboard\n",
    "\t\t#verbose=VERBOSE, validation_split=VALIDATION_SPLIT, callbacks=[tbCallBack])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 34s - loss: 0.1928 - acc: 0.9443 - val_loss: 0.0710 - val_acc: 0.9789\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 35s - loss: 0.0581 - acc: 0.9817 - val_loss: 0.0518 - val_acc: 0.9846\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0352 - acc: 0.9898 - val_loss: 0.0469 - val_acc: 0.9851\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 32s - loss: 0.0237 - acc: 0.9925 - val_loss: 0.0518 - val_acc: 0.9853\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0174 - acc: 0.9946 - val_loss: 0.0445 - val_acc: 0.9876\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 35s - loss: 0.0112 - acc: 0.9965 - val_loss: 0.0469 - val_acc: 0.9874\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0567 - val_acc: 0.9849\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 34s - loss: 0.0067 - acc: 0.9979 - val_loss: 0.0558 - val_acc: 0.9862\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0480 - val_acc: 0.9885\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 34s - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0499 - val_acc: 0.9879\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0063 - acc: 0.9976 - val_loss: 0.0499 - val_acc: 0.9887\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 34s - loss: 0.0068 - acc: 0.9976 - val_loss: 0.0694 - val_acc: 0.9852\n",
      "Epoch 13/20\n",
      "36992/48000 [======================>.......] - ETA: 7s - loss: 0.0062 - acc: 0.9980"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "np.random.seed(1671)  # for reproducibility\n",
    "\n",
    "# network and training\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "IMG_ROWS, IMG_COLS = 28, 28 # input image dimensions\n",
    "NB_CLASSES = 10  # number of outputs = number of digits\n",
    "#INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)\n",
    "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 1)\n",
    "\n",
    "\n",
    "#define the convnet \n",
    "\n",
    "inputs = Input(shape=INPUT_SHAPE)\n",
    "x = Conv2D(20, kernel_size=5, padding=\"same\", activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "x = Conv2D(20, kernel_size=5, padding=\"same\", activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(500, activation='relu')(x)\n",
    "outputs = Dense(NB_CLASSES, activation='softmax')(x)\n",
    "\n",
    "\n",
    "\n",
    "#tbCallBack = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#K.set_image_dim_ordering(\"th\")\n",
    "K.set_image_dim_ordering(\"tf\")\n",
    "\n",
    "# consider them as float and normalize\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 \n",
    "X_test /= 255  \n",
    "\n",
    "# we need a 60K x [1 x 28 x 28] shape as input to the CONVNET\n",
    "#X_train = X_train[:, np.newaxis, :, :]\n",
    "#X_test = X_test[:, np.newaxis, :, :]\n",
    "X_train = X_train[:,:, :, np.newaxis]\n",
    "X_test = X_test[:, :, :, np.newaxis]\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "                         \n",
    "# use Functional API                         \n",
    "                         \n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=OPTIMIZER,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, \n",
    "\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH, \n",
    "        verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "                         \n",
    "                         \n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "official examples: examples/cifar10_cnn.py\n",
    "https://github.com/fchollet/keras/blob/master/examples/cifar10_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 3, 32, 32)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.8419 - acc: 0.3180 - val_loss: 1.5603 - val_acc: 0.4321\n",
      "Epoch 2/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.5521 - acc: 0.4323 - val_loss: 1.4359 - val_acc: 0.4862\n",
      "Epoch 3/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.4261 - acc: 0.4849 - val_loss: 1.2871 - val_acc: 0.5477\n",
      "Epoch 4/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.3418 - acc: 0.5212 - val_loss: 1.1639 - val_acc: 0.5897\n",
      "Epoch 5/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.2736 - acc: 0.5461 - val_loss: 1.0935 - val_acc: 0.6148\n",
      "Epoch 6/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.2144 - acc: 0.5679 - val_loss: 1.0700 - val_acc: 0.6231\n",
      "Epoch 7/200\n",
      "1562/1562 [==============================] - 48s - loss: 1.1663 - acc: 0.5884 - val_loss: 1.0217 - val_acc: 0.6412\n",
      "Epoch 8/200\n",
      "1562/1562 [==============================] - 48s - loss: 1.1244 - acc: 0.6040 - val_loss: 1.0254 - val_acc: 0.6387\n",
      "Epoch 9/200\n",
      "1562/1562 [==============================] - 48s - loss: 1.0839 - acc: 0.6192 - val_loss: 0.9166 - val_acc: 0.6823\n",
      "Epoch 10/200\n",
      "1562/1562 [==============================] - 48s - loss: 1.0528 - acc: 0.6282 - val_loss: 0.8813 - val_acc: 0.6950\n",
      "Epoch 11/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.0271 - acc: 0.6376 - val_loss: 0.8896 - val_acc: 0.6921\n",
      "Epoch 12/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9982 - acc: 0.6501 - val_loss: 0.8498 - val_acc: 0.7086\n",
      "Epoch 13/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9748 - acc: 0.6575 - val_loss: 0.8437 - val_acc: 0.7054\n",
      "Epoch 14/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9466 - acc: 0.6694 - val_loss: 0.8157 - val_acc: 0.7144\n",
      "Epoch 15/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9360 - acc: 0.6735 - val_loss: 0.7881 - val_acc: 0.7290\n",
      "Epoch 16/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9147 - acc: 0.6825 - val_loss: 0.7957 - val_acc: 0.7289\n",
      "Epoch 17/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9048 - acc: 0.6861 - val_loss: 0.7551 - val_acc: 0.7414\n",
      "Epoch 18/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8953 - acc: 0.6903 - val_loss: 0.7897 - val_acc: 0.7299\n",
      "Epoch 19/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8841 - acc: 0.6934 - val_loss: 0.7473 - val_acc: 0.7425\n",
      "Epoch 20/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8757 - acc: 0.6993 - val_loss: 0.7281 - val_acc: 0.7441\n",
      "Epoch 21/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8665 - acc: 0.7003 - val_loss: 0.7373 - val_acc: 0.7525\n",
      "Epoch 22/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8589 - acc: 0.7021 - val_loss: 0.7224 - val_acc: 0.7574\n",
      "Epoch 23/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8469 - acc: 0.7088 - val_loss: 0.7279 - val_acc: 0.7459\n",
      "Epoch 24/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8441 - acc: 0.7092 - val_loss: 0.7168 - val_acc: 0.7573\n",
      "Epoch 25/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8363 - acc: 0.7131 - val_loss: 0.7021 - val_acc: 0.7596\n",
      "Epoch 26/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8304 - acc: 0.7141 - val_loss: 0.7034 - val_acc: 0.7619\n",
      "Epoch 27/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.8276 - acc: 0.7166 - val_loss: 0.6906 - val_acc: 0.7664\n",
      "Epoch 28/200\n",
      "1562/1562 [==============================] - 49s - loss: 0.8188 - acc: 0.7193 - val_loss: 0.6803 - val_acc: 0.7672\n",
      "Epoch 29/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8136 - acc: 0.7211 - val_loss: 0.6782 - val_acc: 0.7707\n",
      "Epoch 30/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.8058 - acc: 0.7238 - val_loss: 0.6768 - val_acc: 0.7718\n",
      "Epoch 31/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.8040 - acc: 0.7269 - val_loss: 0.6953 - val_acc: 0.7652\n",
      "Epoch 32/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8012 - acc: 0.7273 - val_loss: 0.6823 - val_acc: 0.7679\n",
      "Epoch 33/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8010 - acc: 0.7247 - val_loss: 0.6780 - val_acc: 0.7690\n",
      "Epoch 34/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7943 - acc: 0.7280 - val_loss: 0.6783 - val_acc: 0.7771\n",
      "Epoch 35/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7893 - acc: 0.7308 - val_loss: 0.6590 - val_acc: 0.7777\n",
      "Epoch 36/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7931 - acc: 0.7309 - val_loss: 0.6596 - val_acc: 0.7765\n",
      "Epoch 37/200\n",
      "1562/1562 [==============================] - 49s - loss: 0.7884 - acc: 0.7297 - val_loss: 0.6741 - val_acc: 0.7784\n",
      "Epoch 38/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.7836 - acc: 0.7334 - val_loss: 0.6754 - val_acc: 0.7742\n",
      "Epoch 39/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7851 - acc: 0.7330 - val_loss: 0.6656 - val_acc: 0.7840\n",
      "Epoch 40/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.7755 - acc: 0.7343 - val_loss: 0.6679 - val_acc: 0.7775\n",
      "Epoch 41/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7773 - acc: 0.7355 - val_loss: 0.6701 - val_acc: 0.7776\n",
      "Epoch 42/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.7695 - acc: 0.7390 - val_loss: 0.6520 - val_acc: 0.7769\n",
      "Epoch 43/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.7696 - acc: 0.7368 - val_loss: 0.6944 - val_acc: 0.7750\n",
      "Epoch 44/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7703 - acc: 0.7361 - val_loss: 0.7186 - val_acc: 0.7687\n",
      "Epoch 45/200\n",
      "1562/1562 [==============================] - 49s - loss: 0.7701 - acc: 0.7402 - val_loss: 0.6535 - val_acc: 0.7838\n",
      "Epoch 46/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7660 - acc: 0.7392 - val_loss: 0.6489 - val_acc: 0.7856\n",
      "Epoch 47/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7625 - acc: 0.7405 - val_loss: 0.6555 - val_acc: 0.7824\n",
      "Epoch 48/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7700 - acc: 0.7395 - val_loss: 0.6284 - val_acc: 0.7943\n",
      "Epoch 49/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7593 - acc: 0.7403 - val_loss: 0.6648 - val_acc: 0.7845\n",
      "Epoch 50/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7553 - acc: 0.7445 - val_loss: 0.6667 - val_acc: 0.7769\n",
      "Epoch 51/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7566 - acc: 0.7463 - val_loss: 0.6616 - val_acc: 0.7912\n",
      "Epoch 52/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7515 - acc: 0.7463 - val_loss: 0.6511 - val_acc: 0.7777\n",
      "Epoch 53/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7528 - acc: 0.7447 - val_loss: 0.6580 - val_acc: 0.7824\n",
      "Epoch 54/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7575 - acc: 0.7452 - val_loss: 0.6423 - val_acc: 0.7852\n",
      "Epoch 55/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7537 - acc: 0.7448 - val_loss: 0.6370 - val_acc: 0.7971\n",
      "Epoch 56/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7566 - acc: 0.7463 - val_loss: 0.6497 - val_acc: 0.7880\n",
      "Epoch 57/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7581 - acc: 0.7450 - val_loss: 0.6771 - val_acc: 0.7791\n",
      "Epoch 58/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7482 - acc: 0.7481 - val_loss: 0.6282 - val_acc: 0.7951\n",
      "Epoch 59/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7459 - acc: 0.7481 - val_loss: 0.6513 - val_acc: 0.7883\n",
      "Epoch 60/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.7481 - acc: 0.7473 - val_loss: 0.6721 - val_acc: 0.7873\n",
      "Epoch 61/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7527 - acc: 0.7481 - val_loss: 0.6422 - val_acc: 0.7869\n",
      "Epoch 62/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7549 - acc: 0.7464 - val_loss: 0.7088 - val_acc: 0.7871\n",
      "Epoch 63/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7505 - acc: 0.7478 - val_loss: 0.6395 - val_acc: 0.7949\n",
      "Epoch 64/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7542 - acc: 0.7476 - val_loss: 0.6793 - val_acc: 0.7804\n",
      "Epoch 65/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7525 - acc: 0.7487 - val_loss: 0.6603 - val_acc: 0.7955\n",
      "Epoch 66/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7562 - acc: 0.7456 - val_loss: 0.6438 - val_acc: 0.7932\n",
      "Epoch 67/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7477 - acc: 0.7505 - val_loss: 0.6647 - val_acc: 0.7897\n",
      "Epoch 68/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7464 - acc: 0.7501 - val_loss: 0.7045 - val_acc: 0.7619\n",
      "Epoch 69/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7517 - acc: 0.7492 - val_loss: 0.6368 - val_acc: 0.7962\n",
      "Epoch 70/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7510 - acc: 0.7492 - val_loss: 0.6170 - val_acc: 0.7914\n",
      "Epoch 71/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7570 - acc: 0.7474 - val_loss: 0.6405 - val_acc: 0.7881\n",
      "Epoch 72/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7530 - acc: 0.7472 - val_loss: 0.6365 - val_acc: 0.7955\n",
      "Epoch 73/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7477 - acc: 0.7495 - val_loss: 0.6348 - val_acc: 0.7963\n",
      "Epoch 74/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7574 - acc: 0.7488 - val_loss: 0.6764 - val_acc: 0.7797\n",
      "Epoch 75/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7530 - acc: 0.7502 - val_loss: 0.6440 - val_acc: 0.7903\n",
      "Epoch 76/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7537 - acc: 0.7488 - val_loss: 0.6250 - val_acc: 0.7898\n",
      "Epoch 77/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7506 - acc: 0.7482 - val_loss: 0.6578 - val_acc: 0.7812\n",
      "Epoch 78/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7618 - acc: 0.7464 - val_loss: 0.6305 - val_acc: 0.7908\n",
      "Epoch 79/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7461 - acc: 0.7499 - val_loss: 0.6157 - val_acc: 0.8011\n",
      "Epoch 80/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7562 - acc: 0.7511 - val_loss: 0.6903 - val_acc: 0.7718\n",
      "Epoch 81/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7587 - acc: 0.7484 - val_loss: 0.6343 - val_acc: 0.7980\n",
      "Epoch 82/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7576 - acc: 0.7488 - val_loss: 0.6430 - val_acc: 0.7929\n",
      "Epoch 83/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7586 - acc: 0.7474 - val_loss: 0.6778 - val_acc: 0.7814\n",
      "Epoch 84/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7586 - acc: 0.7491 - val_loss: 0.6316 - val_acc: 0.7898\n",
      "Epoch 85/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7626 - acc: 0.7485 - val_loss: 0.6670 - val_acc: 0.7772\n",
      "Epoch 86/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7654 - acc: 0.7466 - val_loss: 0.6531 - val_acc: 0.7829\n",
      "Epoch 87/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7659 - acc: 0.7476 - val_loss: 0.6213 - val_acc: 0.7943\n",
      "Epoch 88/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7595 - acc: 0.7471 - val_loss: 0.6572 - val_acc: 0.7936\n",
      "Epoch 89/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7627 - acc: 0.7485 - val_loss: 0.6766 - val_acc: 0.7847\n",
      "Epoch 90/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7659 - acc: 0.7471 - val_loss: 0.6557 - val_acc: 0.7798\n",
      "Epoch 91/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7647 - acc: 0.7480 - val_loss: 0.6407 - val_acc: 0.7864\n",
      "Epoch 92/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7729 - acc: 0.7462 - val_loss: 0.6780 - val_acc: 0.7774\n",
      "Epoch 93/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7700 - acc: 0.7445 - val_loss: 0.7240 - val_acc: 0.7726\n",
      "Epoch 94/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7835 - acc: 0.7427 - val_loss: 0.7187 - val_acc: 0.7783\n",
      "Epoch 95/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7772 - acc: 0.7451 - val_loss: 0.6922 - val_acc: 0.7776\n",
      "Epoch 96/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7807 - acc: 0.7399 - val_loss: 0.7220 - val_acc: 0.7573\n",
      "Epoch 97/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7833 - acc: 0.7415 - val_loss: 0.7931 - val_acc: 0.7664\n",
      "Epoch 98/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7811 - acc: 0.7421 - val_loss: 0.7408 - val_acc: 0.7739\n",
      "Epoch 99/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7891 - acc: 0.7434 - val_loss: 0.6615 - val_acc: 0.7811\n",
      "Epoch 100/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7916 - acc: 0.7397 - val_loss: 0.6392 - val_acc: 0.7855\n",
      "Epoch 101/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7865 - acc: 0.7420 - val_loss: 0.6914 - val_acc: 0.7863\n",
      "Epoch 102/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7804 - acc: 0.7420 - val_loss: 0.7098 - val_acc: 0.7683\n",
      "Epoch 103/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8002 - acc: 0.7367 - val_loss: 0.6437 - val_acc: 0.7826\n",
      "Epoch 104/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7982 - acc: 0.7363 - val_loss: 0.6996 - val_acc: 0.7632\n",
      "Epoch 105/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.7942 - acc: 0.7393 - val_loss: 0.7571 - val_acc: 0.7694\n",
      "Epoch 106/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8056 - acc: 0.7370 - val_loss: 0.6682 - val_acc: 0.7827\n",
      "Epoch 107/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8020 - acc: 0.7365 - val_loss: 0.7043 - val_acc: 0.7724\n",
      "Epoch 108/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8125 - acc: 0.7350 - val_loss: 0.7922 - val_acc: 0.7569\n",
      "Epoch 109/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8147 - acc: 0.7356 - val_loss: 0.6841 - val_acc: 0.7787\n",
      "Epoch 110/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8121 - acc: 0.7344 - val_loss: 0.6765 - val_acc: 0.7834\n",
      "Epoch 111/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8197 - acc: 0.7314 - val_loss: 0.7067 - val_acc: 0.7749\n",
      "Epoch 112/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8183 - acc: 0.7320 - val_loss: 0.7878 - val_acc: 0.7525\n",
      "Epoch 113/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8207 - acc: 0.7318 - val_loss: 0.7605 - val_acc: 0.7645\n",
      "Epoch 114/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8248 - acc: 0.7304 - val_loss: 0.7975 - val_acc: 0.7694\n",
      "Epoch 115/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8287 - acc: 0.7291 - val_loss: 0.7175 - val_acc: 0.7662\n",
      "Epoch 116/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8252 - acc: 0.7313 - val_loss: 0.7604 - val_acc: 0.7606\n",
      "Epoch 117/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8214 - acc: 0.7309 - val_loss: 0.7342 - val_acc: 0.7661\n",
      "Epoch 118/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8321 - acc: 0.7272 - val_loss: 0.7325 - val_acc: 0.7794\n",
      "Epoch 119/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8257 - acc: 0.7307 - val_loss: 0.7790 - val_acc: 0.7491\n",
      "Epoch 120/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8383 - acc: 0.7254 - val_loss: 0.7248 - val_acc: 0.7565\n",
      "Epoch 121/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8387 - acc: 0.7278 - val_loss: 0.7209 - val_acc: 0.7664\n",
      "Epoch 122/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8475 - acc: 0.7245 - val_loss: 0.7125 - val_acc: 0.7705\n",
      "Epoch 123/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8484 - acc: 0.7247 - val_loss: 0.8578 - val_acc: 0.7158\n",
      "Epoch 124/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8554 - acc: 0.7236 - val_loss: 0.7942 - val_acc: 0.7444\n",
      "Epoch 125/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8515 - acc: 0.7236 - val_loss: 0.8258 - val_acc: 0.7320\n",
      "Epoch 126/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8595 - acc: 0.7226 - val_loss: 0.7495 - val_acc: 0.7565\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 45s - loss: 0.8690 - acc: 0.7176 - val_loss: 0.7765 - val_acc: 0.7381\n",
      "Epoch 128/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8658 - acc: 0.7199 - val_loss: 0.8354 - val_acc: 0.7250\n",
      "Epoch 129/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8752 - acc: 0.7165 - val_loss: 0.7916 - val_acc: 0.7470\n",
      "Epoch 130/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8694 - acc: 0.7189 - val_loss: 0.7194 - val_acc: 0.7773\n",
      "Epoch 131/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8883 - acc: 0.7129 - val_loss: 0.8238 - val_acc: 0.7386\n",
      "Epoch 132/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8852 - acc: 0.7142 - val_loss: 0.8320 - val_acc: 0.7486\n",
      "Epoch 133/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8962 - acc: 0.7105 - val_loss: 0.7942 - val_acc: 0.7646\n",
      "Epoch 134/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.8993 - acc: 0.7110 - val_loss: 0.7570 - val_acc: 0.7641\n",
      "Epoch 135/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.9100 - acc: 0.7086 - val_loss: 0.7555 - val_acc: 0.7561\n",
      "Epoch 136/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9153 - acc: 0.7045 - val_loss: 0.8617 - val_acc: 0.7402\n",
      "Epoch 137/200\n",
      "1562/1562 [==============================] - 49s - loss: 0.9177 - acc: 0.7054 - val_loss: 0.8659 - val_acc: 0.7134\n",
      "Epoch 138/200\n",
      "1562/1562 [==============================] - 51s - loss: 0.9200 - acc: 0.7063 - val_loss: 0.8211 - val_acc: 0.7408\n",
      "Epoch 139/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.9195 - acc: 0.7043 - val_loss: 0.8807 - val_acc: 0.7162\n",
      "Epoch 140/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.9301 - acc: 0.7008 - val_loss: 0.8020 - val_acc: 0.7515\n",
      "Epoch 141/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9338 - acc: 0.6992 - val_loss: 0.7257 - val_acc: 0.7622\n",
      "Epoch 142/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9460 - acc: 0.6987 - val_loss: 0.8238 - val_acc: 0.7457\n",
      "Epoch 143/200\n",
      "1562/1562 [==============================] - 46s - loss: 0.9479 - acc: 0.6977 - val_loss: 0.8114 - val_acc: 0.7327\n",
      "Epoch 144/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.9400 - acc: 0.6974 - val_loss: 0.7696 - val_acc: 0.7605\n",
      "Epoch 145/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.9621 - acc: 0.6919 - val_loss: 0.8306 - val_acc: 0.7195\n",
      "Epoch 146/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.9620 - acc: 0.6937 - val_loss: 0.9242 - val_acc: 0.6963\n",
      "Epoch 147/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.9660 - acc: 0.6906 - val_loss: 0.8947 - val_acc: 0.7141\n",
      "Epoch 148/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.9786 - acc: 0.6882 - val_loss: 0.9112 - val_acc: 0.7049\n",
      "Epoch 149/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.9912 - acc: 0.6821 - val_loss: 0.8694 - val_acc: 0.7216\n",
      "Epoch 150/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.9968 - acc: 0.6830 - val_loss: 0.7281 - val_acc: 0.7619\n",
      "Epoch 151/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.9928 - acc: 0.6833 - val_loss: 0.8681 - val_acc: 0.7098\n",
      "Epoch 152/200\n",
      "1562/1562 [==============================] - 45s - loss: 0.9978 - acc: 0.6803 - val_loss: 0.9141 - val_acc: 0.7051\n",
      "Epoch 153/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0118 - acc: 0.6770 - val_loss: 0.9940 - val_acc: 0.7279\n",
      "Epoch 154/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0175 - acc: 0.6759 - val_loss: 0.9194 - val_acc: 0.6928\n",
      "Epoch 155/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0133 - acc: 0.6798 - val_loss: 0.8959 - val_acc: 0.7013\n",
      "Epoch 156/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0274 - acc: 0.6723 - val_loss: 0.9838 - val_acc: 0.6889\n",
      "Epoch 157/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0285 - acc: 0.6721 - val_loss: 1.0322 - val_acc: 0.6800\n",
      "Epoch 158/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0519 - acc: 0.6656 - val_loss: 1.0039 - val_acc: 0.6788\n",
      "Epoch 159/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0461 - acc: 0.6692 - val_loss: 0.9547 - val_acc: 0.6848\n",
      "Epoch 160/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0463 - acc: 0.6667 - val_loss: 0.8633 - val_acc: 0.7164\n",
      "Epoch 161/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0587 - acc: 0.6621 - val_loss: 0.9955 - val_acc: 0.6581\n",
      "Epoch 162/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0648 - acc: 0.6598 - val_loss: 0.9160 - val_acc: 0.7385\n",
      "Epoch 163/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0713 - acc: 0.6579 - val_loss: 0.9478 - val_acc: 0.7231\n",
      "Epoch 164/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0837 - acc: 0.6580 - val_loss: 0.9480 - val_acc: 0.7146\n",
      "Epoch 165/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0921 - acc: 0.6540 - val_loss: 0.9602 - val_acc: 0.7185\n",
      "Epoch 166/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0873 - acc: 0.6566 - val_loss: 0.9600 - val_acc: 0.6899\n",
      "Epoch 167/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.0976 - acc: 0.6529 - val_loss: 0.9785 - val_acc: 0.6754\n",
      "Epoch 168/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1088 - acc: 0.6480 - val_loss: 0.9339 - val_acc: 0.7071\n",
      "Epoch 169/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1126 - acc: 0.6475 - val_loss: 1.0841 - val_acc: 0.6734\n",
      "Epoch 170/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1176 - acc: 0.6439 - val_loss: 1.0544 - val_acc: 0.6610\n",
      "Epoch 171/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1171 - acc: 0.6448 - val_loss: 1.1075 - val_acc: 0.6323\n",
      "Epoch 172/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1295 - acc: 0.6447 - val_loss: 0.9497 - val_acc: 0.6756\n",
      "Epoch 173/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1356 - acc: 0.6430 - val_loss: 0.9655 - val_acc: 0.7034\n",
      "Epoch 174/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1380 - acc: 0.6382 - val_loss: 0.9889 - val_acc: 0.6910\n",
      "Epoch 175/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1526 - acc: 0.6340 - val_loss: 1.1485 - val_acc: 0.6322\n",
      "Epoch 176/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1467 - acc: 0.6390 - val_loss: 1.0064 - val_acc: 0.6879\n",
      "Epoch 177/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1680 - acc: 0.6302 - val_loss: 1.0579 - val_acc: 0.6624\n",
      "Epoch 178/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1823 - acc: 0.6255 - val_loss: 1.1941 - val_acc: 0.6742\n",
      "Epoch 179/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1713 - acc: 0.6294 - val_loss: 1.1237 - val_acc: 0.6711\n",
      "Epoch 180/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1795 - acc: 0.6296 - val_loss: 0.9699 - val_acc: 0.6849\n",
      "Epoch 181/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1884 - acc: 0.6228 - val_loss: 0.9960 - val_acc: 0.6570\n",
      "Epoch 182/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1990 - acc: 0.6169 - val_loss: 1.0558 - val_acc: 0.6712\n",
      "Epoch 183/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1953 - acc: 0.6209 - val_loss: 1.0992 - val_acc: 0.6392\n",
      "Epoch 184/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.1952 - acc: 0.6196 - val_loss: 1.2611 - val_acc: 0.5709\n",
      "Epoch 185/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2080 - acc: 0.6126 - val_loss: 1.0834 - val_acc: 0.6566\n",
      "Epoch 186/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2182 - acc: 0.6154 - val_loss: 0.9900 - val_acc: 0.6693\n",
      "Epoch 187/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2317 - acc: 0.6141 - val_loss: 1.2105 - val_acc: 0.5931\n",
      "Epoch 188/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2242 - acc: 0.6107 - val_loss: 1.3169 - val_acc: 0.6153\n",
      "Epoch 189/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2426 - acc: 0.6075 - val_loss: 1.0318 - val_acc: 0.6671\n",
      "Epoch 190/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2330 - acc: 0.6090 - val_loss: 1.2002 - val_acc: 0.6043\n",
      "Epoch 191/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2327 - acc: 0.6107 - val_loss: 1.2820 - val_acc: 0.5841\n",
      "Epoch 192/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2393 - acc: 0.6008 - val_loss: 1.2216 - val_acc: 0.6180\n",
      "Epoch 193/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2437 - acc: 0.6046 - val_loss: 1.0641 - val_acc: 0.6565\n",
      "Epoch 194/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2593 - acc: 0.6036 - val_loss: 1.0726 - val_acc: 0.6633\n",
      "Epoch 195/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2693 - acc: 0.5980 - val_loss: 1.2639 - val_acc: 0.5776\n",
      "Epoch 196/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2553 - acc: 0.6001 - val_loss: 1.0606 - val_acc: 0.6775\n",
      "Epoch 197/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2474 - acc: 0.6023 - val_loss: 1.3261 - val_acc: 0.5286\n",
      "Epoch 198/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2676 - acc: 0.5981 - val_loss: 1.0911 - val_acc: 0.6580\n",
      "Epoch 199/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2698 - acc: 0.5997 - val_loss: 1.1107 - val_acc: 0.6162\n",
      "Epoch 200/200\n",
      "1562/1562 [==============================] - 45s - loss: 1.2825 - acc: 0.5918 - val_loss: 1.0595 - val_acc: 0.6466\n"
     ]
    }
   ],
   "source": [
    "'''Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "GPU run command with Theano backend (with TensorFlow, the GPU is automatically used):\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatx=float32 python cifar10_cnn.py\n",
    "It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lenet for  CIFAR10\n",
    "keras_CIFAR10_simple.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 3, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 32, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 277,034\n",
      "Trainable params: 277,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_5_input to have shape (None, 3, 32, 32) but got array with shape (50000, 32, 32, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a9b7b4d15dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n\u001b[1;32m     65\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNB_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALIDATION_SPLIT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \tverbose=VERBOSE)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1430\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1303\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1306\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1307\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_5_input to have shape (None, 3, 32, 32) but got array with shape (50000, 32, 32, 3)"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from quiver_engine import server\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    " \n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(IMG_CHANNELS, IMG_ROWS, IMG_COLS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "#optim = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "\tmetrics=['accuracy'])\n",
    " \n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "\tepochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, \n",
    "\tverbose=VERBOSE)\n",
    " \n",
    "print('Testing...')\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                     batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#server.launch(model)\n",
    "\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "#plt.plot(mo)\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deeper cnn for CIFAR10\n",
    "keras_CIFAR10_V1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/ipykernel_launcher.py:58: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 3 from 1 for 'conv2d_4/convolution' (op: 'Conv2D') with input shapes: [?,1,16,64], [3,3,64,64].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    672\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for 'conv2d_4/convolution' (op: 'Conv2D') with input shapes: [?,1,16,64], [3,3,64,64].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-79f685eeb13b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    464\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3093\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3094\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3095\u001b[0;31m         data_format='NHWC')\n\u001b[0m\u001b[1;32m   3096\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_postprocess_conv2d_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         op=op)\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mwith_space_to_batch\u001b[0;34m(input, dilation_rate, padding, op, filter_shape, spatial_dims, data_format)\u001b[0m\n\u001b[1;32m    329\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dilation_rate must be positive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconst_rate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_spatial_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;31m# We have two padding contributions. The first is used for converting \"SAME\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mop\u001b[0;34m(input_converted, _, padding)\u001b[0m\n\u001b[1;32m    651\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m           \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     return with_space_to_batch(\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_non_atrous_convolution\u001b[0;34m(input, filter, padding, data_format, strides, name)\u001b[0m\n\u001b[1;32m    127\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mconv_dims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"NDHWC\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                                 \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    404\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    766\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    767\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2336\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1717\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for 'conv2d_4/convolution' (op: 'Conv2D') with input shapes: [?,1,16,64], [3,3,64,64]."
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#from quiver_engine import server\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 40\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    " \n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(32, kernel_size=3, padding='same',\n",
    "                        input_shape=(IMG_CHANNELS, IMG_ROWS, IMG_COLS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "#keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# train\n",
    " \n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "\tepochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, \n",
    "\tverbose=VERBOSE)\n",
    "\n",
    "#model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "#                        batch_size=BATCH_SIZE),\n",
    "#                        samples_per_epoch=X_train.shape[0],\n",
    "#                        nb_epoch=NB_EPOCH, \n",
    "#                        verbose=VERBOSE)\n",
    "\n",
    "#server.launch(model)\n",
    "\n",
    "\n",
    "print('Testing...')\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                     batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TensorBoard by Keras callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use saved network and weights to predicting with CIFAR-10\n",
    "keras_EvaluateCIFAR10.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#load model\n",
    "model_architecture = 'cifar10_architecture.json'\n",
    "model_weights = 'cifar10_weights.h5'\n",
    "model = model_from_json(open(model_architecture).read())\n",
    "model.load_weights(model_weights)\n",
    "\n",
    "#load images\n",
    "img_names = ['cat2.jpg', 'dog.jpg']\n",
    "imgs = [np.transpose(scipy.misc.imresize(scipy.misc.imread(img_name), (32, 32)),\n",
    "                     (1, 0, 2)).astype('float32')\n",
    "           for img_name in img_names]\n",
    "imgs = np.array(imgs) / 255\n",
    "\n",
    "# train\n",
    "optim = SGD()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optim,\n",
    "\tmetrics=['accuracy'])\n",
    " \n",
    "predictions = model.predict_classes(imgs)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG 16 (caffe) converted into Keras version\n",
    "https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Can't open attribute (Can't locate attribute: 'layer_names')\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-ef208ae1e027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# Test pretrained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG_16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./vgg16_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-ef208ae1e027>\u001b[0m in \u001b[0;36mVGG_16\u001b[0;34m(weights_path)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   2929\u001b[0m             \u001b[0mfiltered_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2931\u001b[0;31m     \u001b[0mlayer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layer_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2932\u001b[0m     \u001b[0mfiltered_layer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/feedstock_root/build_artefacts/h5py_1491364886027/work/h5py-2.7.0/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/feedstock_root/build_artefacts/h5py_1491364886027/work/h5py-2.7.0/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/h5py/_hl/attrs.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\" Read the value of an attribute.\n\u001b[1;32m     57\u001b[0m         \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty_dataspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/feedstock_root/build_artefacts/h5py_1491364886027/work/h5py-2.7.0/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/feedstock_root/build_artefacts/h5py_1491364886027/work/h5py-2.7.0/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5a.pyx\u001b[0m in \u001b[0;36mh5py.h5a.open (/feedstock_root/build_artefacts/h5py_1491364886027/work/h5py-2.7.0/h5py/h5a.c:2343)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Can't open attribute (Can't locate attribute: 'layer_names')\""
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import cv2, numpy as np\n",
    "\n",
    "# define a VGG16 network\n",
    "\n",
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    #model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #top layer of the VGG net\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    im = cv2.resize(cv2.imread('./img/cat.jpg'), (224, 224)).astype(np.float32)\n",
    "    #im = im.transpose((2,0,1))\n",
    "    #im = np.expand_dims(im, axis=0)\n",
    "    K.set_image_dim_ordering(\"tf\")\n",
    "\n",
    "    # Test pretrained model\n",
    "    model = VGG_16('./vgg16_weights.h5')\n",
    "    optimizer = SGD()\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "    out = model.predict(im)\n",
    "    print(np.argmax(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/io/opencv/modules/imgproc/src/imgwarp.cpp:3492: error: (-215) ssize.width > 0 && ssize.height > 0 in function resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-e558e7b913fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m103.939\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m116.779\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /io/opencv/modules/imgproc/src/imgwarp.cpp:3492: error: (-215) ssize.width > 0 && ssize.height > 0 in function resize\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import cv2, numpy as np\n",
    "\n",
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    im = cv2.resize(cv2.imread('cat.jpg'), (224, 224)).astype(np.float32)\n",
    "    im[:,:,0] -= 103.939\n",
    "    im[:,:,1] -= 116.779\n",
    "    im[:,:,2] -= 123.68\n",
    "    im = im.transpose((2,0,1))\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "\n",
    "    # Test pretrained model\n",
    "    model = VGG_16('./vgg16_weights.h5')\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    out = model.predict(im)\n",
    "    print(np.argmax(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 1 in both shapes must be equal, but are 3 and 64 for 'Assign_90' (op: 'Assign') with input shapes: [3,3,3,64], [3,64,3,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    672\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 1 in both shapes must be equal, but are 3 and 64 for 'Assign_90' (op: 'Assign') with input shapes: [3,3,3,64], [3,64,3,3].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-0fe19506e077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'elephant.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-0fe19506e077>\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    168\u001b[0m                                     \u001b[0mWEIGHTS_PATH_NO_TOP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                                     cache_subdir='models')\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'theano'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_all_kernels_in_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2536\u001b[0m             \u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2538\u001b[0;31m             \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   2968\u001b[0m                              ' elements.')\n\u001b[1;32m   2969\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2970\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2146\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2147\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2148\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2149\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking)\u001b[0m\n\u001b[1;32m    510\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \"\"\"\n\u001b[0;32m--> 512\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    268\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    269\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    271\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     45\u001b[0m   result = _op_def_lib.apply_op(\"Assign\", ref=ref, value=value,\n\u001b[1;32m     46\u001b[0m                                 \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                                 use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    766\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    767\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2336\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1717\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 1 in both shapes must be equal, but are 3 and 64 for 'Assign_90' (op: 'Assign') with input shapes: [3,3,3,64], [3,64,3,3]."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''VGG16 model for Keras.\n",
    "\n",
    "# Reference:\n",
    "\n",
    "- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)\n",
    "\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.engine.topology import get_source_inputs\n",
    "\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def VGG16(include_top=True, weights='imagenet',\n",
    "          input_tensor=None, input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=1000):\n",
    "    \"\"\"Instantiates the VGG16 architecture.\n",
    "\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 244)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 48.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='block5_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = VGG16(include_top=True, weights='imagenet')\n",
    "\n",
    "    img_path = 'elephant.jpg'\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    print('Input image shape:', x.shape)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Application\n",
    "https://keras.io/applications/\n",
    "\n",
    "deep learning models that are made available alongside pre-trained weights. These models can be used for prediction, feature extraction, and fine-tuning.\n",
    "The downloaded models are saved in '/root/.keras/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504458', 'African_elephant', 0.84721768), ('n01871265', 'tusker', 0.088068262), ('n02504013', 'Indian_elephant', 0.064712435)]\n"
     ]
    }
   ],
   "source": [
    "# Classify ImageNet classes with ResNet50\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# will download \"resnet50_weights_tf_dim_ordering_tf_kernels.h5\" &\n",
    "#               \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = './img/elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), \n",
    "# (u'n02504458', u'African_elephant', 0.061040461)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D) (None, 230, 230, 3)   0           input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 112, 112, 64)  9472        zero_padding2d_3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)    (None, 112, 112, 64)  256         conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, 112, 112, 64)  0           bn_conv1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 55, 55, 64)    0           activation_99[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)          (None, 55, 55, 64)    4160        max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, 55, 55, 64)    0           bn2a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)          (None, 55, 55, 64)    36928       activation_100[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, 55, 55, 64)    0           bn2a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)          (None, 55, 55, 256)   16640       activation_101[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)           (None, 55, 55, 256)   16640       max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalization (None, 55, 55, 256)   1024        res2a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_33 (Add)                     (None, 55, 55, 256)   0           bn2a_branch2c[0][0]              \n",
      "                                                                   bn2a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, 55, 55, 256)   0           add_33[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)          (None, 55, 55, 64)    16448       activation_102[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_103 (Activation)      (None, 55, 55, 64)    0           bn2b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)          (None, 55, 55, 64)    36928       activation_103[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_104 (Activation)      (None, 55, 55, 64)    0           bn2b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)          (None, 55, 55, 256)   16640       activation_104[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_34 (Add)                     (None, 55, 55, 256)   0           bn2b_branch2c[0][0]              \n",
      "                                                                   activation_102[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_105 (Activation)      (None, 55, 55, 256)   0           add_34[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)          (None, 55, 55, 64)    16448       activation_105[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_106 (Activation)      (None, 55, 55, 64)    0           bn2c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)          (None, 55, 55, 64)    36928       activation_106[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_107 (Activation)      (None, 55, 55, 64)    0           bn2c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)          (None, 55, 55, 256)   16640       activation_107[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_35 (Add)                     (None, 55, 55, 256)   0           bn2c_branch2c[0][0]              \n",
      "                                                                   activation_105[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_108 (Activation)      (None, 55, 55, 256)   0           add_35[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)          (None, 28, 28, 128)   32896       activation_108[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_109 (Activation)      (None, 28, 28, 128)   0           bn3a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_109[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_110 (Activation)      (None, 28, 28, 128)   0           bn3a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_110[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)           (None, 28, 28, 512)   131584      activation_108[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalization (None, 28, 28, 512)   2048        res3a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_36 (Add)                     (None, 28, 28, 512)   0           bn3a_branch2c[0][0]              \n",
      "                                                                   bn3a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_111 (Activation)      (None, 28, 28, 512)   0           add_36[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)          (None, 28, 28, 128)   65664       activation_111[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_112 (Activation)      (None, 28, 28, 128)   0           bn3b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_112[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_113 (Activation)      (None, 28, 28, 128)   0           bn3b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_113[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_37 (Add)                     (None, 28, 28, 512)   0           bn3b_branch2c[0][0]              \n",
      "                                                                   activation_111[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_114 (Activation)      (None, 28, 28, 512)   0           add_37[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)          (None, 28, 28, 128)   65664       activation_114[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_115 (Activation)      (None, 28, 28, 128)   0           bn3c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_115[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_116 (Activation)      (None, 28, 28, 128)   0           bn3c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_116[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_38 (Add)                     (None, 28, 28, 512)   0           bn3c_branch2c[0][0]              \n",
      "                                                                   activation_114[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_117 (Activation)      (None, 28, 28, 512)   0           add_38[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)          (None, 28, 28, 128)   65664       activation_117[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_118 (Activation)      (None, 28, 28, 128)   0           bn3d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_118[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_119 (Activation)      (None, 28, 28, 128)   0           bn3d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_119[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_39 (Add)                     (None, 28, 28, 512)   0           bn3d_branch2c[0][0]              \n",
      "                                                                   activation_117[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_120 (Activation)      (None, 28, 28, 512)   0           add_39[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)          (None, 14, 14, 256)   131328      activation_120[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_121 (Activation)      (None, 14, 14, 256)   0           bn4a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_121[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_122 (Activation)      (None, 14, 14, 256)   0           bn4a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_122[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)           (None, 14, 14, 1024)  525312      activation_120[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalization (None, 14, 14, 1024)  4096        res4a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_40 (Add)                     (None, 14, 14, 1024)  0           bn4a_branch2c[0][0]              \n",
      "                                                                   bn4a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_123 (Activation)      (None, 14, 14, 1024)  0           add_40[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_123[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_124 (Activation)      (None, 14, 14, 256)   0           bn4b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_124[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_125 (Activation)      (None, 14, 14, 256)   0           bn4b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_125[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_41 (Add)                     (None, 14, 14, 1024)  0           bn4b_branch2c[0][0]              \n",
      "                                                                   activation_123[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_126 (Activation)      (None, 14, 14, 1024)  0           add_41[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_126[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, 14, 14, 256)   0           bn4c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_127[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, 14, 14, 256)   0           bn4c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_128[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_42 (Add)                     (None, 14, 14, 1024)  0           bn4c_branch2c[0][0]              \n",
      "                                                                   activation_126[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, 14, 14, 1024)  0           add_42[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, 14, 14, 256)   0           bn4d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_130[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, 14, 14, 256)   0           bn4d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_43 (Add)                     (None, 14, 14, 1024)  0           bn4d_branch2c[0][0]              \n",
      "                                                                   activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, 14, 14, 1024)  0           add_43[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_132[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4e_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, 14, 14, 256)   0           bn4e_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_133[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4e_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, 14, 14, 256)   0           bn4e_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_134[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4e_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_44 (Add)                     (None, 14, 14, 1024)  0           bn4e_branch2c[0][0]              \n",
      "                                                                   activation_132[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, 14, 14, 1024)  0           add_44[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_135[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4f_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, 14, 14, 256)   0           bn4f_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_136[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4f_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, 14, 14, 256)   0           bn4f_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_137[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4f_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_45 (Add)                     (None, 14, 14, 1024)  0           bn4f_branch2c[0][0]              \n",
      "                                                                   activation_135[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, 14, 14, 1024)  0           add_45[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)          (None, 7, 7, 512)     524800      activation_138[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, 7, 7, 512)     0           bn5a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_139[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, 7, 7, 512)     0           bn5a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_140[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)           (None, 7, 7, 2048)    2099200     activation_138[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalization (None, 7, 7, 2048)    8192        res5a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_46 (Add)                     (None, 7, 7, 2048)    0           bn5a_branch2c[0][0]              \n",
      "                                                                   bn5a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_141 (Activation)      (None, 7, 7, 2048)    0           add_46[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)          (None, 7, 7, 512)     1049088     activation_141[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_142 (Activation)      (None, 7, 7, 512)     0           bn5b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_142[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, 7, 7, 512)     0           bn5b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_143[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_47 (Add)                     (None, 7, 7, 2048)    0           bn5b_branch2c[0][0]              \n",
      "                                                                   activation_141[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_144 (Activation)      (None, 7, 7, 2048)    0           add_47[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)          (None, 7, 7, 512)     1049088     activation_144[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_145 (Activation)      (None, 7, 7, 512)     0           bn5c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_145[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_146 (Activation)      (None, 7, 7, 512)     0           bn5c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_146[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_48 (Add)                     (None, 7, 7, 2048)    0           bn5c_branch2c[0][0]              \n",
      "                                                                   activation_144[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_147 (Activation)      (None, 7, 7, 2048)    0           add_48[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)      (None, 1, 1, 2048)    0           activation_147[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 2048)          0           avg_pool[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "fc1000 (Dense)                   (None, 1000)          2049000     flatten_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights='imagenet')\n",
    "# show ResNet50 model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504458', 'African_elephant', 0.84721756), ('n01871265', 'tusker', 0.088068247), ('n02504013', 'Indian_elephant', 0.064712428)]\n"
     ]
    }
   ],
   "source": [
    "# Extract features with VGG16\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "img_path = './img/elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "features = model.predict(x)\n",
    "\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1000), numpy.ndarray)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, type(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "de_preds = decode_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, list)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(de_preds), type(de_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n02504458', 'African_elephant', 0.84721768),\n",
       " ('n01871265', 'tusker', 0.088068262),\n",
       " ('n02504013', 'Indian_elephant', 0.064712435),\n",
       " ('n01704323', 'triceratops', 3.3450198e-07),\n",
       " ('n02422106', 'hartebeest', 3.0630827e-07)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n"
     ]
    }
   ],
   "source": [
    "# Extract features from an arbitrary intermediate layer with VGG19\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "img_path = './img/elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "block4_pool_features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "=================================================================\n",
      "Total params: 10,585,152\n",
      "Trainable params: 10,585,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# show vgg model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (1, 14, 14, 512))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(block4_pool_features), block4_pool_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fine-tune InceptionV3 on a new set of classes\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "# use functional API manner\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(...)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 172 layers and unfreeze the rest:\n",
    "for layer in model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n"
     ]
    }
   ],
   "source": [
    "# Build InceptionV3 over a custom input tensor\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input\n",
    "\n",
    "# this could also be the output a different Keras model or layer\n",
    "input_tensor = Input(shape=(224, 224, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "\n",
    "model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
