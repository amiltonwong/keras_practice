{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Tensorflow tutorial: Practical guide from getting started to developing complex deep neural network\n",
    "http://cv-tricks.com/tensorflow-tutorial/keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " edit \"~/.keras/keras.json\" to switch  between tensorflow or theano as backends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has two distinct ways of building models\n",
    "1. Sequential model: This is used to implement simple models. You simply keep adding layers to the existing model\n",
    "2. Functional API: To build more complex models using it, models with multiple output, directed acyclic graph etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# start by importing and building a Sequential model.\n",
    "\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layers like Dense(fully connected layer), Activation, Conv2D, MaxPooling2D etc \n",
    "# by calling add function.\n",
    "\n",
    "from keras.layers import Dense, Activation,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(224,224,3)))\n",
    "# This adds a Convolutional layer with 64 filters of size 3 * 3 to the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify the optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the ‘rmsprop’ optimizer to change weights in such a way that the loss \n",
    "# binary_crossentropy’ is minimized at each iteration\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to specify stochastic gradient descent and you want to choose proper \n",
    "# initialization and other hyperparameters:\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feed the data to the model via the fit function\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the evaluate function to test the model\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve a linear regression problem with an example\n",
    "For this example, we will create 100 data points and try to fit them into a line.\n",
    "TrainX has values between –1 and 1, and TrainY has 3 times the TrainX and some randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training data\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    " \n",
    "trX = np.linspace(-1, 1, 101)\n",
    "trY = 3 * trX + np.random.randn(*trX.shape) * 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", activation=\"linear\", units=1, input_dim=1)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=1, output_dim=1, init='uniform', activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model is initialized with weights w: -0.01, b: 0.00\n"
     ]
    }
   ],
   "source": [
    "weights = model.layers[0].get_weights()\n",
    "w_init = weights[0][0][0]\n",
    "b_init = weights[1][0]\n",
    "print('Linear regression model is initialized with weights w: %.2f, b: %.2f' % (w_init, b_init)) \n",
    "## Linear regression model is initialized with weight w: -0.01, b: 0.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train this linear model with our training data of trX and trY,\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "101/101 [==============================] - 0s - loss: 3.1561     \n",
      "Epoch 2/200\n",
      "101/101 [==============================] - 0s - loss: 2.9936     \n",
      "Epoch 3/200\n",
      "101/101 [==============================] - 0s - loss: 2.8468     \n",
      "Epoch 4/200\n",
      "101/101 [==============================] - 0s - loss: 2.7084     \n",
      "Epoch 5/200\n",
      "101/101 [==============================] - 0s - loss: 2.5717     \n",
      "Epoch 6/200\n",
      "101/101 [==============================] - 0s - loss: 2.4452     \n",
      "Epoch 7/200\n",
      "101/101 [==============================] - 0s - loss: 2.3165     \n",
      "Epoch 8/200\n",
      "101/101 [==============================] - 0s - loss: 2.2119     \n",
      "Epoch 9/200\n",
      "101/101 [==============================] - 0s - loss: 2.0843     \n",
      "Epoch 10/200\n",
      "101/101 [==============================] - 0s - loss: 1.9730     \n",
      "Epoch 11/200\n",
      "101/101 [==============================] - 0s - loss: 1.8705     \n",
      "Epoch 12/200\n",
      "101/101 [==============================] - 0s - loss: 1.7845     \n",
      "Epoch 13/200\n",
      "101/101 [==============================] - 0s - loss: 1.6941     \n",
      "Epoch 14/200\n",
      "101/101 [==============================] - 0s - loss: 1.6199     \n",
      "Epoch 15/200\n",
      "101/101 [==============================] - 0s - loss: 1.5501     \n",
      "Epoch 16/200\n",
      "101/101 [==============================] - 0s - loss: 1.4705     \n",
      "Epoch 17/200\n",
      "101/101 [==============================] - 0s - loss: 1.3977     \n",
      "Epoch 18/200\n",
      "101/101 [==============================] - 0s - loss: 1.3297     \n",
      "Epoch 19/200\n",
      "101/101 [==============================] - 0s - loss: 1.2644     \n",
      "Epoch 20/200\n",
      "101/101 [==============================] - 0s - loss: 1.1994     \n",
      "Epoch 21/200\n",
      "101/101 [==============================] - 0s - loss: 1.1345     \n",
      "Epoch 22/200\n",
      "101/101 [==============================] - 0s - loss: 1.0804     \n",
      "Epoch 23/200\n",
      "101/101 [==============================] - 0s - loss: 1.0306     \n",
      "Epoch 24/200\n",
      "101/101 [==============================] - 0s - loss: 0.9756     \n",
      "Epoch 25/200\n",
      "101/101 [==============================] - 0s - loss: 0.9291     \n",
      "Epoch 26/200\n",
      "101/101 [==============================] - 0s - loss: 0.8848     \n",
      "Epoch 27/200\n",
      "101/101 [==============================] - 0s - loss: 0.8432     \n",
      "Epoch 28/200\n",
      "101/101 [==============================] - 0s - loss: 0.8060     \n",
      "Epoch 29/200\n",
      "101/101 [==============================] - 0s - loss: 0.7712     \n",
      "Epoch 30/200\n",
      "101/101 [==============================] - 0s - loss: 0.7369     \n",
      "Epoch 31/200\n",
      "101/101 [==============================] - 0s - loss: 0.6997     \n",
      "Epoch 32/200\n",
      "101/101 [==============================] - 0s - loss: 0.6641     \n",
      "Epoch 33/200\n",
      "101/101 [==============================] - 0s - loss: 0.6357     \n",
      "Epoch 34/200\n",
      "101/101 [==============================] - 0s - loss: 0.6070     \n",
      "Epoch 35/200\n",
      "101/101 [==============================] - 0s - loss: 0.5783     \n",
      "Epoch 36/200\n",
      "101/101 [==============================] - 0s - loss: 0.5533     \n",
      "Epoch 37/200\n",
      "101/101 [==============================] - 0s - loss: 0.5285     \n",
      "Epoch 38/200\n",
      "101/101 [==============================] - 0s - loss: 0.5061     \n",
      "Epoch 39/200\n",
      "101/101 [==============================] - 0s - loss: 0.4839     \n",
      "Epoch 40/200\n",
      "101/101 [==============================] - 0s - loss: 0.4614     \n",
      "Epoch 41/200\n",
      "101/101 [==============================] - 0s - loss: 0.4424     \n",
      "Epoch 42/200\n",
      "101/101 [==============================] - 0s - loss: 0.4257     \n",
      "Epoch 43/200\n",
      "101/101 [==============================] - 0s - loss: 0.4073     \n",
      "Epoch 44/200\n",
      "101/101 [==============================] - 0s - loss: 0.3923     \n",
      "Epoch 45/200\n",
      "101/101 [==============================] - 0s - loss: 0.3775     \n",
      "Epoch 46/200\n",
      "101/101 [==============================] - 0s - loss: 0.3631     \n",
      "Epoch 47/200\n",
      "101/101 [==============================] - ETA: 0s - loss: 0.414 - 0s - loss: 0.3492     \n",
      "Epoch 48/200\n",
      "101/101 [==============================] - 0s - loss: 0.3359     \n",
      "Epoch 49/200\n",
      "101/101 [==============================] - 0s - loss: 0.3220     \n",
      "Epoch 50/200\n",
      "101/101 [==============================] - 0s - loss: 0.3109     \n",
      "Epoch 51/200\n",
      "101/101 [==============================] - 0s - loss: 0.2991     \n",
      "Epoch 52/200\n",
      "101/101 [==============================] - 0s - loss: 0.2894     \n",
      "Epoch 53/200\n",
      "101/101 [==============================] - 0s - loss: 0.2780     \n",
      "Epoch 54/200\n",
      "101/101 [==============================] - 0s - loss: 0.2698     \n",
      "Epoch 55/200\n",
      "101/101 [==============================] - 0s - loss: 0.2596     \n",
      "Epoch 56/200\n",
      "101/101 [==============================] - 0s - loss: 0.2507     \n",
      "Epoch 57/200\n",
      "101/101 [==============================] - 0s - loss: 0.2430     \n",
      "Epoch 58/200\n",
      "101/101 [==============================] - 0s - loss: 0.2349     \n",
      "Epoch 59/200\n",
      "101/101 [==============================] - 0s - loss: 0.2264     \n",
      "Epoch 60/200\n",
      "101/101 [==============================] - 0s - loss: 0.2209     \n",
      "Epoch 61/200\n",
      "101/101 [==============================] - 0s - loss: 0.2148     \n",
      "Epoch 62/200\n",
      "101/101 [==============================] - 0s - loss: 0.2097     \n",
      "Epoch 63/200\n",
      "101/101 [==============================] - ETA: 0s - loss: 0.131 - 0s - loss: 0.2034     \n",
      "Epoch 64/200\n",
      "101/101 [==============================] - 0s - loss: 0.1983     \n",
      "Epoch 65/200\n",
      "101/101 [==============================] - 0s - loss: 0.1928     \n",
      "Epoch 66/200\n",
      "101/101 [==============================] - 0s - loss: 0.1872     \n",
      "Epoch 67/200\n",
      "101/101 [==============================] - 0s - loss: 0.1826     \n",
      "Epoch 68/200\n",
      "101/101 [==============================] - 0s - loss: 0.1785     \n",
      "Epoch 69/200\n",
      "101/101 [==============================] - 0s - loss: 0.1747     \n",
      "Epoch 70/200\n",
      "101/101 [==============================] - 0s - loss: 0.1710     \n",
      "Epoch 71/200\n",
      "101/101 [==============================] - 0s - loss: 0.1676     \n",
      "Epoch 72/200\n",
      "101/101 [==============================] - 0s - loss: 0.1633     \n",
      "Epoch 73/200\n",
      "101/101 [==============================] - 0s - loss: 0.1601     \n",
      "Epoch 74/200\n",
      "101/101 [==============================] - 0s - loss: 0.1577     \n",
      "Epoch 75/200\n",
      "101/101 [==============================] - 0s - loss: 0.1554     \n",
      "Epoch 76/200\n",
      "101/101 [==============================] - 0s - loss: 0.1525     \n",
      "Epoch 77/200\n",
      "101/101 [==============================] - 0s - loss: 0.1499     \n",
      "Epoch 78/200\n",
      "101/101 [==============================] - 0s - loss: 0.1476     \n",
      "Epoch 79/200\n",
      "101/101 [==============================] - 0s - loss: 0.1446     \n",
      "Epoch 80/200\n",
      "101/101 [==============================] - 0s - loss: 0.1421     \n",
      "Epoch 81/200\n",
      "101/101 [==============================] - 0s - loss: 0.1404     \n",
      "Epoch 82/200\n",
      "101/101 [==============================] - 0s - loss: 0.1388     \n",
      "Epoch 83/200\n",
      "101/101 [==============================] - 0s - loss: 0.1365     \n",
      "Epoch 84/200\n",
      "101/101 [==============================] - 0s - loss: 0.1348     \n",
      "Epoch 85/200\n",
      "101/101 [==============================] - 0s - loss: 0.1329     \n",
      "Epoch 86/200\n",
      "101/101 [==============================] - 0s - loss: 0.1313     \n",
      "Epoch 87/200\n",
      "101/101 [==============================] - 0s - loss: 0.1298     \n",
      "Epoch 88/200\n",
      "101/101 [==============================] - 0s - loss: 0.1286     \n",
      "Epoch 89/200\n",
      "101/101 [==============================] - 0s - loss: 0.1272     \n",
      "Epoch 90/200\n",
      "101/101 [==============================] - 0s - loss: 0.1259     \n",
      "Epoch 91/200\n",
      "101/101 [==============================] - 0s - loss: 0.1246     \n",
      "Epoch 92/200\n",
      "101/101 [==============================] - 0s - loss: 0.1231     \n",
      "Epoch 93/200\n",
      "101/101 [==============================] - 0s - loss: 0.1221     \n",
      "Epoch 94/200\n",
      "101/101 [==============================] - 0s - loss: 0.1210     \n",
      "Epoch 95/200\n",
      "101/101 [==============================] - 0s - loss: 0.1201     \n",
      "Epoch 96/200\n",
      "101/101 [==============================] - 0s - loss: 0.1194     \n",
      "Epoch 97/200\n",
      "101/101 [==============================] - 0s - loss: 0.1185     \n",
      "Epoch 98/200\n",
      "101/101 [==============================] - 0s - loss: 0.1176     \n",
      "Epoch 99/200\n",
      "101/101 [==============================] - 0s - loss: 0.1169     \n",
      "Epoch 100/200\n",
      "101/101 [==============================] - 0s - loss: 0.1163     \n",
      "Epoch 101/200\n",
      "101/101 [==============================] - 0s - loss: 0.1153     \n",
      "Epoch 102/200\n",
      "101/101 [==============================] - 0s - loss: 0.1145     \n",
      "Epoch 103/200\n",
      "101/101 [==============================] - 0s - loss: 0.1138     \n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s - loss: 0.1133     \n",
      "Epoch 105/200\n",
      "101/101 [==============================] - 0s - loss: 0.1129     \n",
      "Epoch 106/200\n",
      "101/101 [==============================] - 0s - loss: 0.1122     \n",
      "Epoch 107/200\n",
      "101/101 [==============================] - 0s - loss: 0.1119     \n",
      "Epoch 108/200\n",
      "101/101 [==============================] - 0s - loss: 0.1117     \n",
      "Epoch 109/200\n",
      "101/101 [==============================] - 0s - loss: 0.1114     \n",
      "Epoch 110/200\n",
      "101/101 [==============================] - 0s - loss: 0.1111     \n",
      "Epoch 111/200\n",
      "101/101 [==============================] - 0s - loss: 0.1109     \n",
      "Epoch 112/200\n",
      "101/101 [==============================] - 0s - loss: 0.1105     \n",
      "Epoch 113/200\n",
      "101/101 [==============================] - 0s - loss: 0.1102     \n",
      "Epoch 114/200\n",
      "101/101 [==============================] - 0s - loss: 0.1098     \n",
      "Epoch 115/200\n",
      "101/101 [==============================] - 0s - loss: 0.1092     \n",
      "Epoch 116/200\n",
      "101/101 [==============================] - ETA: 0s - loss: 0.115 - 0s - loss: 0.1088     \n",
      "Epoch 117/200\n",
      "101/101 [==============================] - 0s - loss: 0.1084     \n",
      "Epoch 118/200\n",
      "101/101 [==============================] - 0s - loss: 0.1080     \n",
      "Epoch 119/200\n",
      "101/101 [==============================] - ETA: 0s - loss: 0.099 - 0s - loss: 0.1077     \n",
      "Epoch 120/200\n",
      "101/101 [==============================] - 0s - loss: 0.1076     \n",
      "Epoch 121/200\n",
      "101/101 [==============================] - 0s - loss: 0.1075     \n",
      "Epoch 122/200\n",
      "101/101 [==============================] - 0s - loss: 0.1072     \n",
      "Epoch 123/200\n",
      "101/101 [==============================] - 0s - loss: 0.1072     \n",
      "Epoch 124/200\n",
      "101/101 [==============================] - 0s - loss: 0.1070     \n",
      "Epoch 125/200\n",
      "101/101 [==============================] - 0s - loss: 0.1067     \n",
      "Epoch 126/200\n",
      "101/101 [==============================] - 0s - loss: 0.1065     \n",
      "Epoch 127/200\n",
      "101/101 [==============================] - 0s - loss: 0.1062     \n",
      "Epoch 128/200\n",
      "101/101 [==============================] - 0s - loss: 0.1061     \n",
      "Epoch 129/200\n",
      "101/101 [==============================] - 0s - loss: 0.1057     \n",
      "Epoch 130/200\n",
      "101/101 [==============================] - 0s - loss: 0.1057     \n",
      "Epoch 131/200\n",
      "101/101 [==============================] - 0s - loss: 0.1054     \n",
      "Epoch 132/200\n",
      "101/101 [==============================] - 0s - loss: 0.1054     \n",
      "Epoch 133/200\n",
      "101/101 [==============================] - 0s - loss: 0.1051     \n",
      "Epoch 134/200\n",
      "101/101 [==============================] - 0s - loss: 0.1049     \n",
      "Epoch 135/200\n",
      "101/101 [==============================] - 0s - loss: 0.1047     \n",
      "Epoch 136/200\n",
      "101/101 [==============================] - 0s - loss: 0.1046     \n",
      "Epoch 137/200\n",
      "101/101 [==============================] - 0s - loss: 0.1045     \n",
      "Epoch 138/200\n",
      "101/101 [==============================] - 0s - loss: 0.1044     \n",
      "Epoch 139/200\n",
      "101/101 [==============================] - 0s - loss: 0.1043     \n",
      "Epoch 140/200\n",
      "101/101 [==============================] - 0s - loss: 0.1043     \n",
      "Epoch 141/200\n",
      "101/101 [==============================] - 0s - loss: 0.1042     \n",
      "Epoch 142/200\n",
      "101/101 [==============================] - 0s - loss: 0.1042     \n",
      "Epoch 143/200\n",
      "101/101 [==============================] - 0s - loss: 0.1040     \n",
      "Epoch 144/200\n",
      "101/101 [==============================] - 0s - loss: 0.1040     \n",
      "Epoch 145/200\n",
      "101/101 [==============================] - 0s - loss: 0.1040     \n",
      "Epoch 146/200\n",
      "101/101 [==============================] - 0s - loss: 0.1039     \n",
      "Epoch 147/200\n",
      "101/101 [==============================] - 0s - loss: 0.1041     \n",
      "Epoch 148/200\n",
      "101/101 [==============================] - 0s - loss: 0.1037     \n",
      "Epoch 149/200\n",
      "101/101 [==============================] - 0s - loss: 0.1037     \n",
      "Epoch 150/200\n",
      "101/101 [==============================] - 0s - loss: 0.1036     \n",
      "Epoch 151/200\n",
      "101/101 [==============================] - 0s - loss: 0.1036     \n",
      "Epoch 152/200\n",
      "101/101 [==============================] - 0s - loss: 0.1036     \n",
      "Epoch 153/200\n",
      "101/101 [==============================] - 0s - loss: 0.1036     \n",
      "Epoch 154/200\n",
      "101/101 [==============================] - 0s - loss: 0.1035     \n",
      "Epoch 155/200\n",
      "101/101 [==============================] - 0s - loss: 0.1034     \n",
      "Epoch 156/200\n",
      "101/101 [==============================] - 0s - loss: 0.1034     \n",
      "Epoch 157/200\n",
      "101/101 [==============================] - 0s - loss: 0.1034     \n",
      "Epoch 158/200\n",
      "101/101 [==============================] - 0s - loss: 0.1032     \n",
      "Epoch 159/200\n",
      "101/101 [==============================] - 0s - loss: 0.1032     \n",
      "Epoch 160/200\n",
      "101/101 [==============================] - 0s - loss: 0.1033     \n",
      "Epoch 161/200\n",
      "101/101 [==============================] - 0s - loss: 0.1033     \n",
      "Epoch 162/200\n",
      "101/101 [==============================] - 0s - loss: 0.1032     \n",
      "Epoch 163/200\n",
      "101/101 [==============================] - 0s - loss: 0.1032     \n",
      "Epoch 164/200\n",
      "101/101 [==============================] - 0s - loss: 0.1031     \n",
      "Epoch 165/200\n",
      "101/101 [==============================] - 0s - loss: 0.1031     \n",
      "Epoch 166/200\n",
      "101/101 [==============================] - 0s - loss: 0.1031     \n",
      "Epoch 167/200\n",
      "101/101 [==============================] - 0s - loss: 0.1031     \n",
      "Epoch 168/200\n",
      "101/101 [==============================] - 0s - loss: 0.1032     \n",
      "Epoch 169/200\n",
      "101/101 [==============================] - 0s - loss: 0.1033     \n",
      "Epoch 170/200\n",
      "101/101 [==============================] - 0s - loss: 0.1031     \n",
      "Epoch 171/200\n",
      "101/101 [==============================] - 0s - loss: 0.1032     \n",
      "Epoch 172/200\n",
      "101/101 [==============================] - 0s - loss: 0.1030     \n",
      "Epoch 173/200\n",
      "101/101 [==============================] - 0s - loss: 0.1031     \n",
      "Epoch 174/200\n",
      "101/101 [==============================] - 0s - loss: 0.1030     \n",
      "Epoch 175/200\n",
      "101/101 [==============================] - 0s - loss: 0.1031     \n",
      "Epoch 176/200\n",
      "101/101 [==============================] - 0s - loss: 0.1029     \n",
      "Epoch 177/200\n",
      "101/101 [==============================] - 0s - loss: 0.1030     \n",
      "Epoch 178/200\n",
      "101/101 [==============================] - 0s - loss: 0.1030     \n",
      "Epoch 179/200\n",
      "101/101 [==============================] - 0s - loss: 0.1029     \n",
      "Epoch 180/200\n",
      "101/101 [==============================] - 0s - loss: 0.1029     \n",
      "Epoch 181/200\n",
      "101/101 [==============================] - 0s - loss: 0.1029     \n",
      "Epoch 182/200\n",
      "101/101 [==============================] - 0s - loss: 0.1030     \n",
      "Epoch 183/200\n",
      "101/101 [==============================] - 0s - loss: 0.1029     \n",
      "Epoch 184/200\n",
      "101/101 [==============================] - 0s - loss: 0.1029     \n",
      "Epoch 185/200\n",
      "101/101 [==============================] - 0s - loss: 0.1029     \n",
      "Epoch 186/200\n",
      "101/101 [==============================] - 0s - loss: 0.1029     \n",
      "Epoch 187/200\n",
      "101/101 [==============================] - 0s - loss: 0.1028     \n",
      "Epoch 188/200\n",
      "101/101 [==============================] - 0s - loss: 0.1028     \n",
      "Epoch 189/200\n",
      "101/101 [==============================] - 0s - loss: 0.1028     \n",
      "Epoch 190/200\n",
      "101/101 [==============================] - 0s - loss: 0.1029     \n",
      "Epoch 191/200\n",
      "101/101 [==============================] - 0s - loss: 0.1028     \n",
      "Epoch 192/200\n",
      "101/101 [==============================] - 0s - loss: 0.1028     \n",
      "Epoch 193/200\n",
      "101/101 [==============================] - 0s - loss: 0.1028     \n",
      "Epoch 194/200\n",
      "101/101 [==============================] - 0s - loss: 0.1028     \n",
      "Epoch 195/200\n",
      "101/101 [==============================] - 0s - loss: 0.1028     \n",
      "Epoch 196/200\n",
      "101/101 [==============================] - 0s - loss: 0.1028     \n",
      "Epoch 197/200\n",
      "101/101 [==============================] - 0s - loss: 0.1029     \n",
      "Epoch 198/200\n",
      "101/101 [==============================] - 0s - loss: 0.1027     \n",
      "Epoch 199/200\n",
      "101/101 [==============================] - 0s - loss: 0.1028     \n",
      "Epoch 200/200\n",
      "101/101 [==============================] - 0s - loss: 0.1027     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc62ab4d128>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed the data using fit function\n",
    "\n",
    "model.fit(trX, trY, nb_epoch=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model is trained to have weight w: 3.00, b: 0.01\n"
     ]
    }
   ],
   "source": [
    "# print the weight after training\n",
    "\n",
    "weights = model.layers[0].get_weights()\n",
    "w_final = weights[0][0][0]\n",
    "b_final = weights[1][0]\n",
    "print('Linear regression model is trained to have weight w: %.2f, b: %.2f' % (w_final, b_final))\n",
    "     \n",
    "##Linear regression model is trained to have weight w: 2.94, b: 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3.00013351]], dtype=float32), array([ 0.01157148], dtype=float32)]\n",
      "<class 'list'>\n",
      "2\n",
      "[[ 3.00013351]]\n",
      "(1, 1)\n",
      "[ 3.00013351]\n",
      "<class 'numpy.ndarray'>\n",
      "3.00013\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(weights)\n",
    "print(type(weights))\n",
    "print(len(weights))\n",
    "print(weights[0])\n",
    "print(weights[0].shape)\n",
    "print(weights[0][0])\n",
    "print(type(weights[0][0]))\n",
    "print(weights[0][0][0])\n",
    "print(type(weights[0][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and restoring pre-trained weights using Keras\n",
    "Once you are done with training using Keras, you can save your network weights in HDF5 binary data format. (Require: h5py package installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving weights:\n",
    "\n",
    "model.save_weights(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring pre-trained weights:\n",
    "\n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional API:\n",
    "used for building complex model. Functional API allows you to call models like a function as we do for a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Previous Sequential example: from keras.models import Sequential\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the input, as opposed to (previous) mentioning the input at the end of \n",
    "# the fit function as done in Sequential models\n",
    "\n",
    "from keras.layers import Input\n",
    "# First, define the vision modules\n",
    "\n",
    "# declare a tensor of shape 1 * 28 * 28 by using Input(), not including the batch size.\n",
    "digit_input = Input(shape=(28,28,1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a convolutional layer using the Functional API, we shall have to \n",
    "# specify the variable on which we want to apply the layer\n",
    "\n",
    "x = Conv2D(64, (3, 3))(digit_input)\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "out = Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally,  create a model by specifying the input and output\n",
    "\n",
    "vision_model = Model(digit_input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to specify stochastic gradient descent and you want to choose proper \n",
    "# initialization and other hyperparameters:\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "vision_model.compile(loss='categorical_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-ecb65bc7418a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# feed the data to the model via the fit function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvision_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1430\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[1;32m   1315\u001b[0m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[0m\u001b[1;32m   1317\u001b[0m         \u001b[0m_check_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         _check_loss_and_target_compatibility(y,\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                                                    self._feed_output_names)\n\u001b[1;32m   1314\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[0;32m-> 1315\u001b[0;31m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[1;32m   1317\u001b[0m         \u001b[0m_check_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(y, sample_weight, class_weight, sample_weight_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# feed the data to the model via the fit function\n",
    "\n",
    "vision_model.fit(batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??vision_model.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop VGG convolutional neural network using functional API\n",
    "vgg-16 has 16 layers. As you can see that it takes an input of 224 * 224 * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/vgg16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "classes = 1000\n",
    "\n",
    "img_input = Input(shape=input_shape)\n",
    "# Block 1\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "# Block 2\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "# Block 3\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "# Block 4\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "# Block 5\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = Dense(classes, activation='softmax', name='predictions')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_model = Model(img_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'applications' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-2ac18653c132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'applications' is not defined"
     ]
    }
   ],
   "source": [
    "model = applications.VGG16(weights='imagenet')\n",
    "img = image.load_img('cat.jpeg', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model.predict(x)\n",
    "for results in decode_predictions(preds):\n",
    "    for result in results:\n",
    "        print('Probability %0.2f%% => [%s]' % (100*result[2], result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet 5 for mnist dataset\n",
    "keras_LeNet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 15s - loss: 0.1818 - acc: 0.9450 - val_loss: 0.0624 - val_acc: 0.9813\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0508 - acc: 0.9844 - val_loss: 0.0493 - val_acc: 0.9857\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0336 - acc: 0.9894 - val_loss: 0.0427 - val_acc: 0.9871\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0228 - acc: 0.9926 - val_loss: 0.0436 - val_acc: 0.9868\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0181 - acc: 0.9940 - val_loss: 0.0336 - val_acc: 0.9893\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0126 - acc: 0.9957 - val_loss: 0.0391 - val_acc: 0.9893\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0393 - val_acc: 0.9889\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0083 - acc: 0.9971 - val_loss: 0.0404 - val_acc: 0.9888\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0378 - val_acc: 0.9900\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0066 - acc: 0.9976 - val_loss: 0.0398 - val_acc: 0.9903\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0083 - acc: 0.9971 - val_loss: 0.0378 - val_acc: 0.9907\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0588 - val_acc: 0.9868\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0046 - acc: 0.9983 - val_loss: 0.0414 - val_acc: 0.9906\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0401 - val_acc: 0.9909\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0432 - val_acc: 0.9902\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0438 - val_acc: 0.9906\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 14s - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0465 - val_acc: 0.9913\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0419 - val_acc: 0.9914\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0035 - acc: 0.9989 - val_loss: 0.0467 - val_acc: 0.9899\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 13s - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0466 - val_acc: 0.9903\n",
      " 9696/10000 [============================>.] - ETA: 0s\n",
      "Test score: 0.0372851575539\n",
      "Test accuracy: 0.9912\n",
      "dict_keys(['acc', 'val_loss', 'loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc626b6e278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiKSFAUSERFJigKJiIgkRYFERESS8v8Bx+z633s/S6wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc67fd67908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1671)  # for reproducibility\n",
    "\n",
    "#define the convnet \n",
    "class LeNet:\n",
    "\t@staticmethod\n",
    "\tdef build(input_shape, classes):\n",
    "\t\tmodel = Sequential()\n",
    "\t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(Conv2D(20, kernel_size=5, padding=\"same\",\n",
    "\t\t\tinput_shape=input_shape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(Conv2D(50, kernel_size=5, padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\t\t# Flatten => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(500))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    " \n",
    "\t\t# a softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\treturn model\n",
    "\n",
    "# network and training\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "IMG_ROWS, IMG_COLS = 28, 28 # input image dimensions\n",
    "NB_CLASSES = 10  # number of outputs = number of digits\n",
    "INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "K.set_image_dim_ordering(\"th\")\n",
    "\n",
    "# consider them as float and normalize\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 \n",
    "X_test /= 255  \n",
    "\n",
    "# we need a 60K x [1 x 28 x 28] shape as input to the CONVNET\n",
    "X_train = X_train[:, np.newaxis, :, :]\n",
    "X_test = X_test[:, np.newaxis, :, :]\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# initialize the optimizer and model\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH, \n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "official examples: examples/cifar10_cnn.py\n",
    "https://github.com/fchollet/keras/blob/master/examples/cifar10_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 3, 32, 32)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.8419 - acc: 0.3180 - val_loss: 1.5603 - val_acc: 0.4321\n",
      "Epoch 2/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.5521 - acc: 0.4323 - val_loss: 1.4359 - val_acc: 0.4862\n",
      "Epoch 3/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.4261 - acc: 0.4849 - val_loss: 1.2871 - val_acc: 0.5477\n",
      "Epoch 4/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.3418 - acc: 0.5212 - val_loss: 1.1639 - val_acc: 0.5897\n",
      "Epoch 5/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.2736 - acc: 0.5461 - val_loss: 1.0935 - val_acc: 0.6148\n",
      "Epoch 6/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.2144 - acc: 0.5679 - val_loss: 1.0700 - val_acc: 0.6231\n",
      "Epoch 7/200\n",
      "1562/1562 [==============================] - 48s - loss: 1.1663 - acc: 0.5884 - val_loss: 1.0217 - val_acc: 0.6412\n",
      "Epoch 8/200\n",
      "1562/1562 [==============================] - 48s - loss: 1.1244 - acc: 0.6040 - val_loss: 1.0254 - val_acc: 0.6387\n",
      "Epoch 9/200\n",
      "1562/1562 [==============================] - 48s - loss: 1.0839 - acc: 0.6192 - val_loss: 0.9166 - val_acc: 0.6823\n",
      "Epoch 10/200\n",
      "1562/1562 [==============================] - 48s - loss: 1.0528 - acc: 0.6282 - val_loss: 0.8813 - val_acc: 0.6950\n",
      "Epoch 11/200\n",
      "1562/1562 [==============================] - 47s - loss: 1.0271 - acc: 0.6376 - val_loss: 0.8896 - val_acc: 0.6921\n",
      "Epoch 12/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9982 - acc: 0.6501 - val_loss: 0.8498 - val_acc: 0.7086\n",
      "Epoch 13/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9748 - acc: 0.6575 - val_loss: 0.8437 - val_acc: 0.7054\n",
      "Epoch 14/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9466 - acc: 0.6694 - val_loss: 0.8157 - val_acc: 0.7144\n",
      "Epoch 15/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9360 - acc: 0.6735 - val_loss: 0.7881 - val_acc: 0.7290\n",
      "Epoch 16/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9147 - acc: 0.6825 - val_loss: 0.7957 - val_acc: 0.7289\n",
      "Epoch 17/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.9048 - acc: 0.6861 - val_loss: 0.7551 - val_acc: 0.7414\n",
      "Epoch 18/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8953 - acc: 0.6903 - val_loss: 0.7897 - val_acc: 0.7299\n",
      "Epoch 19/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8841 - acc: 0.6934 - val_loss: 0.7473 - val_acc: 0.7425\n",
      "Epoch 20/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8757 - acc: 0.6993 - val_loss: 0.7281 - val_acc: 0.7441\n",
      "Epoch 21/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8665 - acc: 0.7003 - val_loss: 0.7373 - val_acc: 0.7525\n",
      "Epoch 22/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8589 - acc: 0.7021 - val_loss: 0.7224 - val_acc: 0.7574\n",
      "Epoch 23/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8469 - acc: 0.7088 - val_loss: 0.7279 - val_acc: 0.7459\n",
      "Epoch 24/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8441 - acc: 0.7092 - val_loss: 0.7168 - val_acc: 0.7573\n",
      "Epoch 25/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8363 - acc: 0.7131 - val_loss: 0.7021 - val_acc: 0.7596\n",
      "Epoch 26/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8304 - acc: 0.7141 - val_loss: 0.7034 - val_acc: 0.7619\n",
      "Epoch 27/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.8276 - acc: 0.7166 - val_loss: 0.6906 - val_acc: 0.7664\n",
      "Epoch 28/200\n",
      "1562/1562 [==============================] - 49s - loss: 0.8188 - acc: 0.7193 - val_loss: 0.6803 - val_acc: 0.7672\n",
      "Epoch 29/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8136 - acc: 0.7211 - val_loss: 0.6782 - val_acc: 0.7707\n",
      "Epoch 30/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.8058 - acc: 0.7238 - val_loss: 0.6768 - val_acc: 0.7718\n",
      "Epoch 31/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.8040 - acc: 0.7269 - val_loss: 0.6953 - val_acc: 0.7652\n",
      "Epoch 32/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8012 - acc: 0.7273 - val_loss: 0.6823 - val_acc: 0.7679\n",
      "Epoch 33/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.8010 - acc: 0.7247 - val_loss: 0.6780 - val_acc: 0.7690\n",
      "Epoch 34/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7943 - acc: 0.7280 - val_loss: 0.6783 - val_acc: 0.7771\n",
      "Epoch 35/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7893 - acc: 0.7308 - val_loss: 0.6590 - val_acc: 0.7777\n",
      "Epoch 36/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7931 - acc: 0.7309 - val_loss: 0.6596 - val_acc: 0.7765\n",
      "Epoch 37/200\n",
      "1562/1562 [==============================] - 49s - loss: 0.7884 - acc: 0.7297 - val_loss: 0.6741 - val_acc: 0.7784\n",
      "Epoch 38/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.7836 - acc: 0.7334 - val_loss: 0.6754 - val_acc: 0.7742\n",
      "Epoch 39/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7851 - acc: 0.7330 - val_loss: 0.6656 - val_acc: 0.7840\n",
      "Epoch 40/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.7755 - acc: 0.7343 - val_loss: 0.6679 - val_acc: 0.7775\n",
      "Epoch 41/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7773 - acc: 0.7355 - val_loss: 0.6701 - val_acc: 0.7776\n",
      "Epoch 42/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.7695 - acc: 0.7390 - val_loss: 0.6520 - val_acc: 0.7769\n",
      "Epoch 43/200\n",
      "1562/1562 [==============================] - 47s - loss: 0.7696 - acc: 0.7368 - val_loss: 0.6944 - val_acc: 0.7750\n",
      "Epoch 44/200\n",
      "1562/1562 [==============================] - 48s - loss: 0.7703 - acc: 0.7361 - val_loss: 0.7186 - val_acc: 0.7687\n",
      "Epoch 45/200\n",
      "1513/1562 [============================>.] - ETA: 1s - loss: 0.7708 - acc: 0.7402"
     ]
    }
   ],
   "source": [
    "'''Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "GPU run command with Theano backend (with TensorFlow, the GPU is automatically used):\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatx=float32 python cifar10_cnn.py\n",
    "It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lenet for  CIFAR10\n",
    "keras_CIFAR10_simple.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "X_train shape: (50000, 3, 32, 32)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 3)         9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 16, 1)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 16, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 277,034\n",
      "Trainable params: 277,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_19_input to have shape (None, 32, 32, 3) but got array with shape (50000, 3, 32, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-331ddac6fb0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n\u001b[1;32m     65\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNB_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALIDATION_SPLIT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \tverbose=VERBOSE)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1430\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1303\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1306\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1307\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/tf1.1_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_19_input to have shape (None, 32, 32, 3) but got array with shape (50000, 3, 32, 32)"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from quiver_engine import server\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    " \n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(IMG_CHANNELS, IMG_ROWS, IMG_COLS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "#optim = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "\tmetrics=['accuracy'])\n",
    " \n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "\tepochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, \n",
    "\tverbose=VERBOSE)\n",
    " \n",
    "print('Testing...')\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                     batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#server.launch(model)\n",
    "\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "#plt.plot(mo)\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deeper cnn for CIFAR10\n",
    "keras_CIFAR10_V1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#from quiver_engine import server\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 40\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    " \n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(32, kernel_size=3, padding='same',\n",
    "                        input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# train\n",
    " \n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "\tepochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, \n",
    "\tverbose=VERBOSE)\n",
    "\n",
    "#model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "#                        batch_size=BATCH_SIZE),\n",
    "#                        samples_per_epoch=X_train.shape[0],\n",
    "#                        nb_epoch=NB_EPOCH, \n",
    "#                        verbose=VERBOSE)\n",
    "\n",
    "#server.launch(model)\n",
    "\n",
    "\n",
    "print('Testing...')\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                     batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
