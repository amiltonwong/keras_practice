{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started with the Keras Sequential model\n",
    "https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# create a Sequential model by passing a list of layer instances to the constructor\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can also simply add layers via the .add() method:\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation\n",
    "Before training a model, you need to configure the learning process, which is done via the `compile` method. It receives three arguments:\n",
    "An optimizer,\n",
    "A loss function,\n",
    "A list of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\n",
    "# For custom metrics\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "For training a model, you will typically use the  `fit` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a single-input model with 2 classes (binary classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a single-input model with 10 classes (categorical classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 5s - loss: 2.3323     \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s - loss: 2.3716     \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s - loss: 2.2950     \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s - loss: 2.2938     \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s - loss: 2.2702     \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s - loss: 2.2875     \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s - loss: 2.2996     \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s - loss: 2.2905     \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s - loss: 2.2874     \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s - loss: 2.2890     \n",
      "20/20 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.32940864563\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3294086456298828"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 100, 3), array([[[ 0.4731096 ,  0.07340136,  0.26995034],\n",
       "         [ 0.43379746,  0.61717208,  0.31052778],\n",
       "         [ 0.684096  ,  0.96713331,  0.49324173],\n",
       "         ..., \n",
       "         [ 0.59749404,  0.59777033,  0.90309463],\n",
       "         [ 0.94548972,  0.88653189,  0.68036542],\n",
       "         [ 0.60232064,  0.45322063,  0.23977082]],\n",
       " \n",
       "        [[ 0.37816352,  0.50634953,  0.17580065],\n",
       "         [ 0.17927697,  0.42384099,  0.61122288],\n",
       "         [ 0.89041784,  0.71034089,  0.36445946],\n",
       "         ..., \n",
       "         [ 0.51683753,  0.05753093,  0.89581237],\n",
       "         [ 0.26422618,  0.50639963,  0.91120402],\n",
       "         [ 0.13829305,  0.91124815,  0.67447327]],\n",
       " \n",
       "        [[ 0.88107916,  0.2306567 ,  0.03732703],\n",
       "         [ 0.87988387,  0.49989518,  0.26367294],\n",
       "         [ 0.91084141,  0.99695066,  0.08361236],\n",
       "         ..., \n",
       "         [ 0.10956301,  0.9147392 ,  0.75739921],\n",
       "         [ 0.88792723,  0.30615034,  0.68734699],\n",
       "         [ 0.32192226,  0.66330075,  0.41735446]],\n",
       " \n",
       "        ..., \n",
       "        [[ 0.09839464,  0.04731462,  0.55217311],\n",
       "         [ 0.51148005,  0.1850355 ,  0.26257896],\n",
       "         [ 0.88030792,  0.86654487,  0.84522241],\n",
       "         ..., \n",
       "         [ 0.94358103,  0.41690481,  0.21405344],\n",
       "         [ 0.03981048,  0.72962356,  0.47672841],\n",
       "         [ 0.82896581,  0.02621622,  0.65644975]],\n",
       " \n",
       "        [[ 0.40811558,  0.76995247,  0.3212282 ],\n",
       "         [ 0.34919334,  0.3568827 ,  0.90025547],\n",
       "         [ 0.97773175,  0.93449659,  0.39266153],\n",
       "         ..., \n",
       "         [ 0.74042758,  0.92464603,  0.11360751],\n",
       "         [ 0.50023606,  0.47583364,  0.07838474],\n",
       "         [ 0.50194055,  0.76694484,  0.14192034]],\n",
       " \n",
       "        [[ 0.60656674,  0.62050101,  0.77646112],\n",
       "         [ 0.7726036 ,  0.04495591,  0.01814923],\n",
       "         [ 0.75509772,  0.9312689 ,  0.050522  ],\n",
       "         ..., \n",
       "         [ 0.82053002,  0.39031081,  0.55372104],\n",
       "         [ 0.4487387 ,  0.89197669,  0.00482192],\n",
       "         [ 0.47365857,  0.39865403,  0.4222666 ]]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0,:].shape, x_train[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
